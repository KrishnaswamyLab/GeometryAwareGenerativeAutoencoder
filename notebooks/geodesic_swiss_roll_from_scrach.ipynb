{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import wandb\n",
    "import sys\n",
    "import matplotlib.pyplot as plt\n",
    "import scprep\n",
    "import pandas as pd\n",
    "sys.path.append('../src/')\n",
    "from model import AEDist\n",
    "from omegaconf import OmegaConf\n",
    "import os\n",
    "import glob\n",
    "import numpy as np\n",
    "import torch\n",
    "from torch import nn\n",
    "from torch.autograd import grad\n",
    "adjoint = False\n",
    "if adjoint:\n",
    "    from torchdiffeq import odeint_adjoint as odeint\n",
    "else:\n",
    "    from torchdiffeq import odeint\n",
    "import torch.optim as optim\n",
    "from torch.autograd.functional import jacobian\n",
    "\n",
    "def compute_jacobian_function(f, x, create_graph=True, retain_graph=True):\n",
    "    \"\"\"\n",
    "    Compute the Jacobian of the decoder wrt a batch of points in the latent space using an efficient broadcasting approach.\n",
    "    :param model: The VAE model.\n",
    "    :param z_batch: A batch of points in the latent space (tensor).\n",
    "    :return: A batch of Jacobian matrices.\n",
    "    \"\"\"\n",
    "    # z_batch = z_batch.clone().detach().requires_grad_(True)\n",
    "    x = x.clone()\n",
    "    x.requires_grad_(True)\n",
    "    # model.no_grad()\n",
    "    output = f(x)\n",
    "    batch_size, output_dim, latent_dim = *output.shape, x.shape[-1]\n",
    "\n",
    "    # Use autograd's grad function to get gradients for each output dimension\n",
    "    jacobian = torch.zeros(batch_size, output_dim, latent_dim).to(x.device)\n",
    "    for i in range(output_dim):\n",
    "        grad_outputs = torch.zeros(batch_size, output_dim).to(x.device)\n",
    "        grad_outputs[:, i] = 1.0\n",
    "        gradients = grad(outputs=output, inputs=x, grad_outputs=grad_outputs, create_graph=create_graph, retain_graph=retain_graph, only_inputs=True)[0]\n",
    "        jacobian[:, i, :] = gradients\n",
    "    return jacobian\n",
    "\n",
    "def pullback_metric(x, fcn, create_graph=True, retain_graph=True):\n",
    "    jac = compute_jacobian_function(fcn, x, create_graph, retain_graph)\n",
    "    metric = torch.einsum('Nki,Nkj->Nij', jac, jac)\n",
    "    return metric\n",
    "\n",
    "# def pullback_metric2(x, fcn):\n",
    "#     jac = compute_jacobian_function(fcn, x)\n",
    "#     metric = torch.einsum('Nki,Nkj->Nij', jac, jac)\n",
    "#     return metric\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Failed to detect the name of this notebook, you can set it manually with the WANDB_NOTEBOOK_NAME environment variable to enable code saving.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mxingzhis\u001b[0m. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n"
     ]
    }
   ],
   "source": [
    "wandb.login()\n",
    "api = wandb.Api()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/gpfs/gibbs/pi/krishnaswamy_smita/xingzhi/.conda_envs/geosink/lib/python3.11/site-packages/pytorch_lightning/utilities/parsing.py:269: UserWarning: Attribute 'activation_fn' is an instance of `nn.Module` and is already saved during checkpointing. It is recommended to ignore them using `self.save_hyperparameters(ignore=['activation_fn'])`.\n",
      "  rank_zero_warn(\n"
     ]
    }
   ],
   "source": [
    "entity = \"xingzhis\"\n",
    "project = \"dmae\"\n",
    "run_id = 'iio2bb24'\n",
    "run = api.run(f\"{entity}/{project}/{run_id}\")\n",
    "folder_path = '../src/wandb/'\n",
    "cfg = OmegaConf.create(run.config)\n",
    "folder_list = glob.glob(f\"{folder_path}*{run.id}*\")\n",
    "ckpt_files = glob.glob(f\"{folder_list[0]}/files/*.ckpt\")\n",
    "ckpt_path = ckpt_files[0]\n",
    "data_path2 = os.path.join(cfg.data.root, cfg.data.name + cfg.data.filetype)\n",
    "data = np.load(data_path2, allow_pickle=True)\n",
    "model = AEDist.load_from_checkpoint(ckpt_path)\n",
    "x_tensor = torch.tensor(data['data'], dtype=torch.float32, device=model.device)\n",
    "x_tensor_normalized = model.normalize(x_tensor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([3000, 3, 3])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pullback_metric(x_tensor_normalized, model.encoder).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ODEFunc(nn.Module):\n",
    "\n",
    "    def __init__(self):\n",
    "        super(ODEFunc, self).__init__()\n",
    "\n",
    "        self.net = nn.Sequential(\n",
    "            nn.Linear(3, 50),\n",
    "            nn.Tanh(),\n",
    "            nn.Linear(50, 3),\n",
    "        )\n",
    "\n",
    "        for m in self.net.modules():\n",
    "            if isinstance(m, nn.Linear):\n",
    "                nn.init.normal_(m.weight, mean=0, std=0.1)\n",
    "                nn.init.constant_(m.bias, val=0)\n",
    "\n",
    "    def forward(self, t, x):\n",
    "        return self.net(x)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# class DeltaLengthNet(torch.nn.Module):\n",
    "#     def __init__(self, fcn):\n",
    "#         super(DeltaLengthNet, self).__init__()\n",
    "#         self.fcn = fcn\n",
    "#         self.odefunc = ODEFunc()\n",
    "    \n",
    "#     def forward(self, t, x):\n",
    "#         metric = pullback_metric(x, self.fcn, create_graph=False, retain_graph=True)\n",
    "#         xdot = self.odefunc(t, x)\n",
    "#         return torch.sqrt(torch.einsum('Ni,Nij,Nj->N', xdot, metric, xdot))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "metric = pullback_metric(x_tensor_normalized, model.encoder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([3000])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.einsum('Ni,Nij,Nj->N', x_tensor_normalized, metric, x_tensor_normalized).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for model.encoder.net[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dl = DeltaLengthNet(model.encoder)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 3])\n",
      "torch.Size([5, 3])\n",
      "torch.Size([5, 3])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/tmp.OTD9fhobVM/ipykernel_835654/175121352.py:12: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  x0 = torch.tensor(tswiss_roll[start,:]).cpu() #Start point\n",
      "/tmp/tmp.OTD9fhobVM/ipykernel_835654/175121352.py:13: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  x1 = torch.tensor(tswiss_roll[starttwo,:]).cpu()\n",
      "/tmp/tmp.OTD9fhobVM/ipykernel_835654/175121352.py:14: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  x2 = torch.tensor(tswiss_roll[startthree,:]).cpu()\n",
      "/tmp/tmp.OTD9fhobVM/ipykernel_835654/175121352.py:15: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  x3 = torch.tensor(tswiss_roll[startfour,:]).cpu()\n",
      "/tmp/tmp.OTD9fhobVM/ipykernel_835654/175121352.py:16: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  x4 = torch.tensor(tswiss_roll[startfive,:]).cpu()\n",
      "/tmp/tmp.OTD9fhobVM/ipykernel_835654/175121352.py:17: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  xfin = torch.tensor(tswiss_roll[end,:]).cpu()\n"
     ]
    }
   ],
   "source": [
    "tswiss_roll = x_tensor_normalized\n",
    "# Swiss roll random integer\n",
    "npts = len(tswiss_roll)\n",
    "start = np.random.randint(0,npts,size=1)\n",
    "starttwo = np.random.randint(0,npts,size=1)\n",
    "startthree = np.random.randint(0,npts,size=1)\n",
    "startfour = np.random.randint(0,npts,size=1)\n",
    "startfive= np.random.randint(0,npts,size=1)\n",
    "end = np.random.randint(0,npts,size=1)\n",
    "#Select start and end points for NeuralODE\n",
    "\n",
    "x0 = torch.tensor(tswiss_roll[start,:]).cpu() #Start point\n",
    "x1 = torch.tensor(tswiss_roll[starttwo,:]).cpu() \n",
    "x2 = torch.tensor(tswiss_roll[startthree,:]).cpu() \n",
    "x3 = torch.tensor(tswiss_roll[startfour,:]).cpu() \n",
    "x4 = torch.tensor(tswiss_roll[startfive,:]).cpu() \n",
    "xfin = torch.tensor(tswiss_roll[end,:]).cpu() \n",
    "xbatch = torch.cat((x0,x1,x2,x3,x4),0)\n",
    "endbtch = torch.cat((xfin,xfin,xfin,xfin,xfin),0)\n",
    "\n",
    "\n",
    "print(xfin.shape)\n",
    "print(xbatch.shape)\n",
    "print(endbtch.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_t = torch.linspace(0,1,2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-0.1956,  1.2660,  1.6567],\n",
       "        [ 0.4090,  0.7648,  0.7226],\n",
       "        [ 0.1463,  0.8104,  0.6780],\n",
       "        [ 0.8805,  0.9799,  1.3358],\n",
       "        [ 1.0704, -0.2958,  0.6806]])"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xbatch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 2.9277, -9.8357],\n",
       "        [ 1.2194,  2.6928],\n",
       "        [10.2101, -0.0439],\n",
       "        [-8.2807, -2.8404],\n",
       "        [ 3.1774,  4.7731]], grad_fn=<AddmmBackward0>)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.encoder(xbatch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dl(batch_t, xbatch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-0.1956,  1.2660,  1.6567],\n",
       "        [ 0.4090,  0.7648,  0.7226],\n",
       "        [ 0.1463,  0.8104,  0.6780],\n",
       "        [ 0.8805,  0.9799,  1.3358],\n",
       "        [ 1.0704, -0.2958,  0.6806]])"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xbatch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_t = torch.linspace(0, 1, 100)\n",
    "odefunc = ODEFunc()\n",
    "xs = odeint(odefunc, xbatch, batch_t)\n",
    "ts = batch_t"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "fcn = model.encoder\n",
    "original_shape = xs.shape\n",
    "xs_flat = xs.view(-1, xs.shape[2])\n",
    "metric_flat = pullback_metric(xs_flat, fcn, create_graph=False, retain_graph=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([500, 3, 3])"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "metric_flat.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ODEFunc(nn.Module):\n",
    "\n",
    "    def __init__(self, fcn):\n",
    "        super(ODEFunc, self).__init__()\n",
    "        self.fcn = fcn\n",
    "\n",
    "        self.net = nn.Sequential(\n",
    "            nn.Linear(3, 50),\n",
    "            nn.Tanh(),\n",
    "            nn.Linear(50, 2), # coefficients\n",
    "        )\n",
    "\n",
    "    def forward(self, t, x):\n",
    "        xs_flat = x.view(-1, xs.shape[2])\n",
    "        coefs = self.net(xs_flat)\n",
    "        jac = compute_jacobian_function(fcn, xs_flat, create_graph=True, retain_graph=True)\n",
    "        U, S, Vt = torch.linalg.svd(jac, full_matrices=False)\n",
    "        velo_flat = torch.einsum('ij,ijk->ik', coefs, Vt)\n",
    "        velo = velo_flat.view(x.shape[0], x.shape[1], -1)\n",
    "        return velo\n",
    "\n",
    "fcn = model.encoder\n",
    "odefunc = ODEFunc(fcn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "original_shape = xs.shape\n",
    "xs_flat = xs.view(-1, xs.shape[2])\n",
    "# xs_flat = xs_flat.detach().clone()\n",
    "xs_flat.requires_grad_(True)\n",
    "jac = compute_jacobian_function(fcn, xs_flat, create_graph=False, retain_graph=True)\n",
    "# metric_flat = pullback_metric(xs_flat, fcn, create_graph=False, retain_graph=True)\n",
    "metric_flat = torch.einsum('Nki,Nkj->Nij', jac, jac)\n",
    "xdot = odefunc(ts, xs)\n",
    "xdot_flat = xdot.view(-1, xdot.shape[2])\n",
    "l_flat = torch.sqrt(torch.einsum('Ni,Nij,Nj->N', xdot_flat, metric_flat, xdot_flat))\n",
    "l = l_flat.view(original_shape[0], original_shape[1])\n",
    "l_batch = l.mean(axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-0.1956,  1.2660,  1.6567],\n",
       "        [ 0.4090,  0.7648,  0.7226],\n",
       "        [ 0.1463,  0.8104,  0.6780],\n",
       "        ...,\n",
       "        [ 0.0764,  0.8725,  0.5668],\n",
       "        [ 0.7312,  1.1494,  1.1908],\n",
       "        [ 0.9777, -0.1643,  0.6917]], grad_fn=<ViewBackward0>)"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xs_flat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[  5.9738,   1.7593,  -4.4991],\n",
       "         [  6.9808,   0.6456,  11.7341]],\n",
       "\n",
       "        [[  2.7883,  -1.4000,   1.8339],\n",
       "         [ -3.4731,  -1.0087,   1.4866]],\n",
       "\n",
       "        [[  9.2566,   4.5395,   2.4293],\n",
       "         [  3.2944,  -2.4549,   1.8112]],\n",
       "\n",
       "        ...,\n",
       "\n",
       "        [[ -2.7907,  -0.3447,   6.7974],\n",
       "         [  4.1363,  -1.0368,   7.1594]],\n",
       "\n",
       "        [[-12.2313,   0.9186,  -9.5081],\n",
       "         [  2.2051,  -1.1680,  -5.7299]],\n",
       "\n",
       "        [[-13.7632,  -1.8136, -33.5215],\n",
       "         [  7.4836,   1.0632,  -3.3347]]])"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "jac"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "# scprep.plot.scatter3d(xs_flat.detach().cpu().numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "U, S, Vt = torch.linalg.svd(jac, full_matrices=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([500, 3, 2])"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Vt.permute(0,2,1).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[ 0.4745,  0.0371,  0.8795],\n",
       "         [-0.8510, -0.2363,  0.4690]],\n",
       "\n",
       "        [[ 0.9997, -0.0246,  0.0035],\n",
       "         [-0.0173, -0.5892,  0.8078]],\n",
       "\n",
       "        [[ 0.8998,  0.3528,  0.2567],\n",
       "         [ 0.2680, -0.9112,  0.3128]],\n",
       "\n",
       "        ...,\n",
       "\n",
       "        [[ 0.1440, -0.1021,  0.9843],\n",
       "         [ 0.9851, -0.0801, -0.1524]],\n",
       "\n",
       "        [[-0.7582,  0.0487, -0.6502],\n",
       "         [ 0.6280, -0.2137, -0.7483]],\n",
       "\n",
       "        [[-0.3782, -0.0498, -0.9244],\n",
       "         [ 0.9152,  0.1299, -0.3814]]])"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Vt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# torch.einsum('ni,ni->n', Vt[:,0,:], Vt[:,1,:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-1.0350,  1.0839,  0.8666],\n",
       "        [-1.0350,  1.0839,  0.8666],\n",
       "        [-1.0350,  1.0839,  0.8666],\n",
       "        [-1.0350,  1.0839,  0.8666],\n",
       "        [-1.0350,  1.0839,  0.8666]])"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "endbtch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-0.1956,  1.2660,  1.6567],\n",
       "        [ 0.4090,  0.7648,  0.7226],\n",
       "        [ 0.1463,  0.8104,  0.6780],\n",
       "        [ 0.8805,  0.9799,  1.3358],\n",
       "        [ 1.0704, -0.2958,  0.6806]])"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xbatch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# t = torch.linspace(0., 25., 100)\n",
    "# true_y0 = torch.tensor([[2., 0.]])\n",
    "# true_A = torch.tensor([[-0.1, 2.0], [-2.0, -0.1]])\n",
    "# class Lambda(nn.Module):\n",
    "\n",
    "#     def forward(self, t, y):\n",
    "#         return torch.mm(y**3, true_A)\n",
    "\n",
    "\n",
    "# with torch.no_grad():\n",
    "#     true_y = odeint(Lambda(), true_y0, t, method='dopri5')\n",
    "\n",
    "# def get_batch():\n",
    "#     s = torch.from_numpy(np.random.choice(np.arange(100 - 10, dtype=np.int64), 32, replace=False))\n",
    "#     batch_y0 = true_y[s]  # (M, D)\n",
    "#     batch_t = t[:10]  # (T)\n",
    "#     batch_y = torch.stack([true_y[s + i] for i in range(10)], dim=0)  # (T, M, D)\n",
    "#     return batch_y0, batch_t, batch_y\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'get_batch' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[31], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m batch_y0, batch_t, batch_y \u001b[39m=\u001b[39m get_batch()\n",
      "\u001b[0;31mNameError\u001b[0m: name 'get_batch' is not defined"
     ]
    }
   ],
   "source": [
    "batch_y0, batch_t, batch_y = get_batch()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([32, 1, 2])"
      ]
     },
     "execution_count": 107,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "batch_y0.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([10])"
      ]
     },
     "execution_count": 108,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "batch_t.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 0.0941,  0.0650,  0.0978],\n",
       "        [ 0.0519, -0.0360,  0.0672],\n",
       "        [ 0.1275,  0.0517,  0.0312],\n",
       "        [ 0.1361,  0.0184, -0.0385],\n",
       "        [-0.0176, -0.0065, -0.0898]], grad_fn=<AddmmBackward0>)"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ode(batch_t, xbatch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[ 1.2636, -1.1970,  0.0490],\n",
       "         [ 1.1355,  0.8826, -0.7435],\n",
       "         [ 0.7154, -0.8976,  0.5071],\n",
       "         [ 0.1271, -0.2776,  0.7833],\n",
       "         [-1.0314, -0.0115,  0.6272]],\n",
       "\n",
       "        [[ 1.3732, -1.1329,  0.1448],\n",
       "         [ 1.1956,  0.8479, -0.6767],\n",
       "         [ 0.8547, -0.8465,  0.5392],\n",
       "         [ 0.2690, -0.2591,  0.7487],\n",
       "         [-1.0580, -0.0182,  0.5400]]], grad_fn=<CopySlices>)"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "odeint(ode, xbatch, batch_t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DeltaLengthNet(\n",
       "  (fcn): MLP(\n",
       "    (net): Sequential(\n",
       "      (0): Linear(in_features=3, out_features=256, bias=True)\n",
       "      (1): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (2): ReLU()\n",
       "      (3): Linear(in_features=256, out_features=128, bias=True)\n",
       "      (4): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (5): ReLU()\n",
       "      (6): Linear(in_features=128, out_features=64, bias=True)\n",
       "      (7): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (8): ReLU()\n",
       "      (9): Linear(in_features=64, out_features=2, bias=True)\n",
       "    )\n",
       "  )\n",
       "  (odefunc): ODEFunc(\n",
       "    (net): Sequential(\n",
       "      (0): Linear(in_features=3, out_features=50, bias=True)\n",
       "      (1): Tanh()\n",
       "      (2): Linear(in_features=50, out_features=3, bias=True)\n",
       "    )\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "xj = x_tensor_normalized[:100,:].clone()\n",
    "xj.requires_grad = True\n",
    "jac2 = torch.autograd.functional.jacobian(fcn, xj)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "xj = x_tensor_normalized[:100,:].clone()\n",
    "xj.requires_grad = True\n",
    "jac1 = compute_jacobian_function(fcn, xj, create_graph=False, retain_graph=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-0.8684,  0.0236, -1.0067],\n",
       "        [ 0.1840,  0.2444, -1.2358],\n",
       "        [ 0.2437, -1.3371,  0.1722],\n",
       "        [ 0.0489,  0.6453, -0.4259],\n",
       "        [ 0.3651,  0.4967,  0.3923],\n",
       "        [ 0.4829,  0.6382, -0.4590],\n",
       "        [ 0.6718,  1.1707, -1.2243],\n",
       "        [ 0.1208, -0.7065, -1.5939],\n",
       "        [-1.1967, -1.2995,  0.1857],\n",
       "        [-1.3850, -0.9415,  0.5508],\n",
       "        [-0.0245,  1.2696, -0.8185],\n",
       "        [ 0.7865, -0.8530, -1.0688],\n",
       "        [-0.8079,  0.3914, -1.1201],\n",
       "        [ 0.4048,  0.4748,  1.5497],\n",
       "        [-0.1745,  0.1158, -1.3989],\n",
       "        [-0.9508,  0.6480, -1.1287],\n",
       "        [-1.3634,  0.9255,  0.4177],\n",
       "        [ 0.5199,  0.7263,  0.4666],\n",
       "        [-0.2398,  1.0528, -1.2614],\n",
       "        [ 0.6575, -0.4875, -1.3386],\n",
       "        [ 0.5762,  0.2497,  0.6565],\n",
       "        [ 0.1421,  0.4722, -0.3928],\n",
       "        [ 0.1000,  0.2369,  1.4754],\n",
       "        [ 0.4500, -0.7788,  0.8218],\n",
       "        [ 0.1868, -0.5579,  0.6494],\n",
       "        [ 1.1157, -0.2390, -1.0569],\n",
       "        [ 1.1488,  1.2061, -0.4805],\n",
       "        [-1.4308, -0.1632, -0.4137],\n",
       "        [-0.7912, -0.3485,  1.0076],\n",
       "        [-0.6588, -0.1301,  0.9504],\n",
       "        [ 0.1218, -0.8075,  0.6557],\n",
       "        [ 0.7467,  1.0640, -1.2134],\n",
       "        [ 0.2991, -1.4306,  0.3919],\n",
       "        [-1.1960,  1.1702,  0.5723],\n",
       "        [ 1.3031, -0.0322,  0.4898],\n",
       "        [ 0.2926, -1.0115,  0.5941],\n",
       "        [ 1.1734,  0.5943, -0.7879],\n",
       "        [ 0.8412,  0.7213, -0.9954],\n",
       "        [-1.0042,  0.7523,  0.5409],\n",
       "        [ 0.5102,  0.2633,  0.5017],\n",
       "        [-0.9873,  0.3615,  0.7606],\n",
       "        [ 0.1797,  0.1708, -0.7242],\n",
       "        [-1.1217, -1.0145, -0.9860],\n",
       "        [ 1.2954,  0.7007, -0.2412],\n",
       "        [ 1.0501,  0.4985,  0.4906],\n",
       "        [ 0.7585,  0.2406,  0.1477],\n",
       "        [-1.3811, -0.4734,  0.0888],\n",
       "        [ 1.2482, -0.2140,  1.1564],\n",
       "        [ 0.2525,  0.9536,  0.6752],\n",
       "        [ 1.3415,  1.2899,  0.4482],\n",
       "        [ 0.0104,  0.6394, -0.5222],\n",
       "        [-1.2655,  0.7979, -0.7026],\n",
       "        [-1.1770, -0.2263, -0.2769],\n",
       "        [ 0.7002, -0.1886,  1.0423],\n",
       "        [ 0.5964, -0.6972,  0.4359],\n",
       "        [ 0.1774, -0.1512, -0.2536],\n",
       "        [ 1.2879, -0.1962,  0.9129],\n",
       "        [ 1.3383, -0.7358,  0.5950],\n",
       "        [ 0.5441,  0.1542, -0.0387],\n",
       "        [-0.2612,  0.6277,  1.8358],\n",
       "        [-0.3341,  0.0795,  0.8359],\n",
       "        [-0.0948,  0.6437,  0.8544],\n",
       "        [ 1.3812, -0.5045,  0.1453],\n",
       "        [ 1.2046, -0.5484,  0.7710],\n",
       "        [-0.1014,  0.6327, -1.2749],\n",
       "        [-0.0310,  0.6646, -0.3381],\n",
       "        [-1.3917, -1.1231, -0.5676],\n",
       "        [ 0.4036,  0.7993, -1.3516],\n",
       "        [ 1.2674,  1.3364, -0.0441],\n",
       "        [-0.4363, -0.7276,  0.7576],\n",
       "        [-1.2504, -1.2923, -0.0668],\n",
       "        [ 1.3149,  0.9351,  0.0143],\n",
       "        [-0.0479, -0.4113,  0.7343],\n",
       "        [ 0.1481, -0.9669, -1.3324],\n",
       "        [-1.1336,  0.3225,  0.5866],\n",
       "        [ 0.0160, -0.1312, -1.5160],\n",
       "        [ 0.5586, -0.2343,  0.2901],\n",
       "        [-1.4798,  0.0131, -0.6863],\n",
       "        [ 1.2151,  1.1982,  0.1378],\n",
       "        [ 0.6961, -0.8981, -1.0592],\n",
       "        [-1.6078,  0.7901, -0.1383],\n",
       "        [-0.6715,  0.0751,  0.9227],\n",
       "        [ 1.1252, -1.0115, -0.6736],\n",
       "        [ 0.3801, -0.9603,  0.1103],\n",
       "        [-1.1842,  0.6663, -0.8219],\n",
       "        [-0.8411,  0.0690,  0.5626],\n",
       "        [ 0.0221, -0.1272, -0.4328],\n",
       "        [ 0.1540, -0.2103,  0.6812],\n",
       "        [ 0.7920,  0.4152, -1.2365],\n",
       "        [ 0.2057,  0.7259,  0.8146],\n",
       "        [-0.7739,  0.4076,  0.6881],\n",
       "        [-0.6323,  0.8391, -1.3670],\n",
       "        [ 1.2712, -0.3587, -0.0703],\n",
       "        [-0.2148,  0.7930,  0.8021],\n",
       "        [ 0.5404, -0.1927, -0.0580],\n",
       "        [ 0.3110, -0.6655, -1.3529],\n",
       "        [ 1.2778, -1.2637,  0.6356],\n",
       "        [-1.0005, -0.4988, -1.1334],\n",
       "        [-0.1453, -1.1207, -1.4250],\n",
       "        [ 0.6142, -0.2898, -0.3602]], requires_grad=True)"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xj"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[[-1.6000e-01,  1.2661e+00,  7.0687e-01],\n",
       "          [-8.0331e-02, -4.2649e-02, -1.2482e-01],\n",
       "          [ 5.6130e-02,  1.2781e-02,  5.5852e-03],\n",
       "          ...,\n",
       "          [ 1.1844e-02, -1.0015e-01, -3.5252e-02],\n",
       "          [ 9.6427e-02, -1.2403e-02, -3.5353e-02],\n",
       "          [-4.5646e-03, -9.6671e-03, -3.0431e-02]],\n",
       "\n",
       "         [[ 4.0855e+00,  1.5588e+00, -5.6226e+00],\n",
       "          [ 1.1061e-01,  1.9104e-02,  1.1722e-01],\n",
       "          [-8.5327e-02, -4.5160e-02,  4.8423e-02],\n",
       "          ...,\n",
       "          [-2.4106e-01, -1.2250e-01,  3.6439e-01],\n",
       "          [-1.5442e-01, -8.9653e-02,  1.9829e-01],\n",
       "          [ 2.7556e-02,  7.2798e-03,  7.6086e-02]]],\n",
       "\n",
       "\n",
       "        [[[-2.3466e-02, -3.7578e-02,  5.1181e-02],\n",
       "          [-2.8150e+00,  4.4632e-01, -6.3662e-01],\n",
       "          [ 1.1519e-03,  1.3879e-02, -3.1905e-02],\n",
       "          ...,\n",
       "          [ 8.4265e-03, -2.8990e-02,  7.0546e-02],\n",
       "          [ 1.3097e-01,  9.3238e-03,  1.6862e-01],\n",
       "          [-6.4703e-02, -4.5413e-03, -1.6575e-01]],\n",
       "\n",
       "         [[-7.3698e-02, -8.2990e-03, -1.8725e-01],\n",
       "          [ 3.3823e+00,  2.5409e+00,  2.9287e+00],\n",
       "          [-1.3722e-02, -2.3671e-03,  1.6424e-02],\n",
       "          ...,\n",
       "          [-6.4377e-02, -1.1758e-03, -2.1815e-01],\n",
       "          [ 6.2148e-02,  1.8759e-03, -1.7449e-01],\n",
       "          [ 2.4043e-03, -1.7163e-02, -8.4693e-02]]],\n",
       "\n",
       "\n",
       "        [[[ 3.3123e-02,  1.5571e-02, -1.2480e-01],\n",
       "          [ 5.8349e-02,  4.4876e-03,  6.7039e-02],\n",
       "          [-5.5837e+00, -3.2698e+00, -8.1522e-01],\n",
       "          ...,\n",
       "          [ 1.1663e-02,  2.2044e-02, -9.9176e-02],\n",
       "          [ 1.2572e-01,  7.1852e-02, -6.8051e-02],\n",
       "          [ 3.4647e-02,  5.1781e-02,  1.8934e-01]],\n",
       "\n",
       "         [[-1.2395e-01, -3.4100e-02,  8.7172e-02],\n",
       "          [-2.0849e-02, -2.0577e-02, -2.7745e-02],\n",
       "          [ 3.1033e+00, -9.1412e-01, -5.8073e+00],\n",
       "          ...,\n",
       "          [-1.2212e-01, -4.1262e-02,  7.3758e-02],\n",
       "          [-1.0968e-01, -5.3848e-02, -5.0698e-02],\n",
       "          [ 1.0526e-01,  5.4838e-02,  1.2891e-01]]],\n",
       "\n",
       "\n",
       "        ...,\n",
       "\n",
       "\n",
       "        [[[ 6.3200e-02, -1.1535e-01, -1.5432e-03],\n",
       "          [-5.8294e-02, -3.7057e-02, -8.3029e-02],\n",
       "          [ 4.2107e-02,  7.4241e-03, -7.5024e-03],\n",
       "          ...,\n",
       "          [-1.2159e+00,  1.3510e+00, -6.4907e-01],\n",
       "          [ 1.6493e-01, -1.4707e-02,  7.0688e-04],\n",
       "          [-1.9804e-02, -1.6288e-02, -3.2930e-02]],\n",
       "\n",
       "         [[-1.6049e-01, -9.3890e-02,  3.2024e-01],\n",
       "          [ 8.5835e-02,  1.7031e-02,  1.2489e-02],\n",
       "          [-6.4649e-02, -5.3782e-02,  3.5860e-02],\n",
       "          ...,\n",
       "          [ 2.5236e+00,  1.4687e+00, -3.5012e+00],\n",
       "          [-7.3315e-02, -1.1243e-01,  8.9533e-02],\n",
       "          [ 2.9283e-02, -1.0852e-03,  5.9606e-02]]],\n",
       "\n",
       "\n",
       "        [[[-6.2544e-02, -7.8705e-02,  1.5733e-01],\n",
       "          [ 1.4809e-01,  6.7708e-03,  9.3738e-02],\n",
       "          [ 1.3745e-01,  7.7723e-02,  1.2173e-02],\n",
       "          ...,\n",
       "          [-3.8015e-02, -9.9669e-02,  1.6923e-01],\n",
       "          [-3.1411e+00, -2.8884e-01, -3.5441e+00],\n",
       "          [-5.0210e-02, -2.1163e-02, -2.3682e-02]],\n",
       "\n",
       "         [[-1.0723e-01, -6.6601e-02,  8.5696e-02],\n",
       "          [ 6.1070e-02, -3.0239e-02,  1.9431e-01],\n",
       "          [-6.7415e-02, -4.0322e-02, -3.5284e-02],\n",
       "          ...,\n",
       "          [-9.9597e-02, -8.3947e-02,  2.5059e-02],\n",
       "          [ 5.7756e-01,  6.5474e-01, -4.0697e+00],\n",
       "          [ 3.1261e-02, -9.4129e-03,  4.2902e-02]]],\n",
       "\n",
       "\n",
       "        [[[-3.6794e-02,  3.2706e-03, -5.6565e-02],\n",
       "          [ 5.5622e-02,  2.8608e-02,  8.9719e-03],\n",
       "          [-9.3004e-03,  6.6484e-02,  1.2526e-01],\n",
       "          ...,\n",
       "          [-3.9116e-02, -2.5823e-03, -6.7389e-02],\n",
       "          [-1.1656e-01, -5.2285e-04, -1.7586e-01],\n",
       "          [-2.3164e+00, -2.3683e+00, -1.3593e+00]],\n",
       "\n",
       "         [[-4.0678e-02, -6.5621e-03,  1.4239e-01],\n",
       "          [-7.3782e-02, -2.5514e-02, -1.5292e-02],\n",
       "          [ 7.3358e-02, -1.0905e-02,  3.6647e-02],\n",
       "          ...,\n",
       "          [ 8.6329e-04, -9.1389e-03,  1.8000e-01],\n",
       "          [-6.4045e-03, -2.2794e-02,  1.5676e-01],\n",
       "          [ 4.6618e-01,  1.2115e+00, -6.7884e+00]]]])"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "jac2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[-6.2720e-01,  7.2077e-02,  1.2819e+00],\n",
       "         [ 1.9052e+00,  3.7060e-01, -1.6726e+00]],\n",
       "\n",
       "        [[ 5.3103e-01,  4.5460e-01,  2.0450e+00],\n",
       "         [ 6.8977e-01,  2.8719e-01,  3.3891e+00]],\n",
       "\n",
       "        [[-3.4549e-01,  6.7609e-02,  5.4959e-01],\n",
       "         [ 1.1801e+00, -9.2412e-01, -2.2275e+00]],\n",
       "\n",
       "        [[ 4.2492e-01,  2.0359e-02,  4.6186e-01],\n",
       "         [-2.0389e+00,  8.3883e-01,  1.3473e+00]],\n",
       "\n",
       "        [[-3.8764e-01,  8.1049e-01,  1.4613e+00],\n",
       "         [ 1.1917e+00, -2.1976e-01, -1.0997e+00]],\n",
       "\n",
       "        [[ 4.2549e-01, -4.8525e-01,  2.0891e+00],\n",
       "         [-8.0178e-01,  8.0972e-02, -1.8817e+00]],\n",
       "\n",
       "        [[ 3.8723e-01,  1.7810e-01, -3.5687e+00],\n",
       "         [ 4.5282e-01, -6.9495e-01,  1.8389e-02]],\n",
       "\n",
       "        [[ 3.4725e-01,  5.0117e-01, -1.8377e-01],\n",
       "         [-1.6966e-02,  3.3439e-01,  1.3539e-01]],\n",
       "\n",
       "        [[-1.4895e+00, -4.5776e-01,  6.0408e-01],\n",
       "         [-1.0796e+00,  5.8865e-02, -1.5685e+00]],\n",
       "\n",
       "        [[ 1.5767e-01,  6.6500e-02,  5.0274e-01],\n",
       "         [-1.8245e+00, -2.7839e-03, -3.5228e-01]],\n",
       "\n",
       "        [[ 8.5711e-01,  6.6797e-01,  2.5484e-01],\n",
       "         [-2.5433e+00, -3.1096e-01,  1.8796e-01]],\n",
       "\n",
       "        [[-3.3651e-01, -1.9323e-01, -1.4639e+00],\n",
       "         [ 1.3180e+00, -1.5317e-01, -3.8116e-01]],\n",
       "\n",
       "        [[-1.6612e-01,  2.6821e-01,  2.2911e+00],\n",
       "         [ 1.5875e+00,  2.8974e-01, -3.2058e-01]],\n",
       "\n",
       "        [[ 4.9411e-01,  5.0439e-01, -1.5014e+00],\n",
       "         [ 2.9414e-01,  4.9280e-01,  1.4065e+00]],\n",
       "\n",
       "        [[ 1.0120e+00, -2.7350e-02,  3.2455e+00],\n",
       "         [-2.1319e-03, -4.1945e-01,  1.0260e-03]],\n",
       "\n",
       "        [[ 1.4397e+00, -2.3155e-01,  2.3130e+00],\n",
       "         [ 7.8517e-01, -3.6099e-01,  1.6190e-01]],\n",
       "\n",
       "        [[-1.4627e-01, -4.4233e-01, -3.7772e-01],\n",
       "         [-1.5350e+00, -7.4292e-02,  5.3023e-01]],\n",
       "\n",
       "        [[-2.7638e+00,  1.8562e-01,  1.2167e-01],\n",
       "         [ 1.3325e+00, -9.7649e-03, -1.4448e-01]],\n",
       "\n",
       "        [[-4.1499e-02, -4.1151e-01,  1.8373e+00],\n",
       "         [ 1.4996e+00, -2.9313e-01,  4.8995e+00]],\n",
       "\n",
       "        [[ 1.3707e+00,  9.9480e-02,  1.0222e+00],\n",
       "         [ 5.2844e-01, -2.8815e-01, -1.9784e-01]],\n",
       "\n",
       "        [[-2.0756e+00,  3.3802e-01, -5.8975e-01],\n",
       "         [-5.5621e-01, -2.6589e-01,  7.9005e-01]],\n",
       "\n",
       "        [[ 5.3556e-01, -2.0705e-01, -1.9130e+00],\n",
       "         [-3.4727e+00,  1.4064e+00,  1.4887e+00]],\n",
       "\n",
       "        [[ 2.3579e+00,  7.2591e-01,  2.0943e+00],\n",
       "         [-7.3404e-01,  7.3751e-01,  1.5584e+00]],\n",
       "\n",
       "        [[-5.3254e+00, -1.4499e+00, -5.6464e+00],\n",
       "         [-1.9086e+00,  1.7457e-01, -1.9826e+00]],\n",
       "\n",
       "        [[-1.5584e+00, -1.0167e+00, -6.2613e-01],\n",
       "         [ 6.6022e-01,  2.9420e-01, -1.7395e+00]],\n",
       "\n",
       "        [[ 1.8544e+00,  1.9229e-01,  2.2773e-01],\n",
       "         [ 2.9210e-01, -5.5769e-01,  7.0799e-02]],\n",
       "\n",
       "        [[ 6.7674e-01,  1.1672e-01, -1.5858e+00],\n",
       "         [-4.5164e-01,  4.8515e-01,  5.5801e-01]],\n",
       "\n",
       "        [[ 1.4554e+00, -5.9923e-03,  4.6082e-01],\n",
       "         [-4.6404e-01,  4.8728e-02, -6.1382e-02]],\n",
       "\n",
       "        [[-2.2428e-01,  1.1259e-01,  3.4696e+00],\n",
       "         [-1.1648e-02,  1.5613e-01, -5.7778e-01]],\n",
       "\n",
       "        [[-8.0236e-02,  6.9844e-02, -5.9335e-02],\n",
       "         [ 6.8954e-01,  2.1659e-01,  7.3282e-01]],\n",
       "\n",
       "        [[-8.5163e-02, -1.2549e+00,  3.5394e-01],\n",
       "         [ 2.4139e-01,  3.0412e-01, -8.8401e-01]],\n",
       "\n",
       "        [[ 3.6075e-01,  8.3800e-02, -4.1675e+00],\n",
       "         [ 4.2114e-01, -6.6756e-01, -3.1261e-01]],\n",
       "\n",
       "        [[ 1.7231e+00,  6.7506e-01,  2.1635e+00],\n",
       "         [ 1.0806e+00, -4.2646e-01, -1.8534e+00]],\n",
       "\n",
       "        [[ 9.2377e-01,  2.2054e-01,  1.8447e+00],\n",
       "         [-1.3105e+00,  4.5750e-01,  9.1795e-01]],\n",
       "\n",
       "        [[ 5.8326e-02,  4.9015e-01,  3.9825e-01],\n",
       "         [-8.3445e-01, -3.1606e-01, -9.8657e-02]],\n",
       "\n",
       "        [[ 3.5714e-01,  4.6490e-01,  2.0867e+00],\n",
       "         [ 1.6312e+00,  2.9871e-01, -4.7951e-01]],\n",
       "\n",
       "        [[ 1.9492e-01,  9.4728e-01,  1.3871e+00],\n",
       "         [-2.3572e+00, -6.1471e-01, -1.2669e+00]],\n",
       "\n",
       "        [[ 1.4895e+00,  5.3749e-02, -2.8036e-01],\n",
       "         [ 3.4181e-01, -5.7328e-01,  2.9836e-02]],\n",
       "\n",
       "        [[-9.8926e-01, -9.6837e-01, -1.5801e+00],\n",
       "         [-1.9073e+00, -4.7069e-01, -1.5203e+00]],\n",
       "\n",
       "        [[-3.2037e+00,  4.8463e-01,  9.2478e-01],\n",
       "         [ 1.6661e+00, -2.5150e-01, -7.4763e-01]],\n",
       "\n",
       "        [[-4.4179e-01,  9.7900e-02, -1.8835e-01],\n",
       "         [-3.3325e-01, -2.3674e-01, -1.3260e+00]],\n",
       "\n",
       "        [[ 2.7443e-01, -7.4261e-02, -1.5581e+00],\n",
       "         [-2.2509e-02,  1.1243e+00, -3.7455e+00]],\n",
       "\n",
       "        [[-7.6515e-01,  6.2147e-01, -8.8039e-03],\n",
       "         [ 6.5354e-01, -8.0779e-02, -1.4906e-01]],\n",
       "\n",
       "        [[ 1.0564e+00,  2.6806e-01, -1.4151e+00],\n",
       "         [-8.5914e-01, -2.1624e-01,  2.3787e-01]],\n",
       "\n",
       "        [[ 4.2924e+00,  5.9460e-01,  2.1635e+00],\n",
       "         [ 5.2106e-01, -8.9660e-02, -7.4492e-01]],\n",
       "\n",
       "        [[ 1.3574e+00,  5.8642e-01, -9.0704e-02],\n",
       "         [-3.6754e-01,  2.5024e-01, -7.0138e-01]],\n",
       "\n",
       "        [[ 1.3564e+00,  1.2274e-02, -5.6916e-02],\n",
       "         [-1.5722e+00, -3.9659e-01, -9.8992e-01]],\n",
       "\n",
       "        [[-3.4722e+00,  1.5067e-01, -4.1720e-01],\n",
       "         [ 6.0580e-01,  1.7537e-01,  6.5898e-01]],\n",
       "\n",
       "        [[ 1.4355e+00,  6.3271e-01,  3.1539e-01],\n",
       "         [-4.3293e-01, -3.3207e-02,  1.2548e+00]],\n",
       "\n",
       "        [[ 1.5278e+00,  1.0041e-01, -1.3475e-01],\n",
       "         [-3.8854e-01,  1.5837e-01, -2.4758e+00]],\n",
       "\n",
       "        [[ 3.5298e-01, -3.4381e-01,  6.0529e-01],\n",
       "         [-6.6295e-01, -2.1241e-01,  1.3262e-01]],\n",
       "\n",
       "        [[ 1.9992e+00, -3.3851e-01,  1.5151e+00],\n",
       "         [-2.2759e-02, -3.4476e-01,  1.0736e+00]],\n",
       "\n",
       "        [[ 2.1458e-01, -9.2608e-02, -1.0837e+00],\n",
       "         [-2.0271e+00, -1.7829e-01, -7.8847e-01]],\n",
       "\n",
       "        [[-1.0792e-01, -4.3202e-03,  3.6692e+00],\n",
       "         [ 3.9408e-01,  4.8378e-01,  5.0626e-01]],\n",
       "\n",
       "        [[-3.1169e+00, -1.4440e+00, -2.4517e-01],\n",
       "         [ 7.6139e-01, -1.1083e-01, -2.1274e+00]],\n",
       "\n",
       "        [[-6.9193e-01, -5.9581e-01, -4.5819e-01],\n",
       "         [-6.0959e-01,  1.5864e+00,  7.0859e-01]],\n",
       "\n",
       "        [[-2.0530e+00,  3.6601e-01, -9.6490e-02],\n",
       "         [ 3.7084e-01, -1.2835e-02,  1.5964e-01]],\n",
       "\n",
       "        [[-1.7973e+00, -2.2820e-02, -1.6139e-01],\n",
       "         [ 1.2459e+00,  1.0725e-01, -1.2471e-02]],\n",
       "\n",
       "        [[ 5.0162e-01, -3.2092e-01, -2.5086e+00],\n",
       "         [-9.9996e-01,  2.6205e-01, -1.2972e+00]],\n",
       "\n",
       "        [[ 1.2617e+00,  5.5342e-01, -2.1157e+00],\n",
       "         [-1.4304e+00,  1.0087e-01,  1.4836e+00]],\n",
       "\n",
       "        [[-6.1356e-01, -2.1333e-01,  1.3835e+00],\n",
       "         [ 1.7686e+00, -7.1101e-02,  4.7558e-01]],\n",
       "\n",
       "        [[-1.5834e+00,  2.1233e-01,  4.9641e-02],\n",
       "         [ 1.0429e+00,  5.9969e-02, -7.2131e-02]],\n",
       "\n",
       "        [[ 9.4796e-01,  1.4257e-01, -1.8697e-01],\n",
       "         [-6.9226e-02, -2.2171e-01, -1.2396e+00]],\n",
       "\n",
       "        [[-7.4588e-01,  2.5116e-01,  7.8923e-01],\n",
       "         [ 1.1931e+00,  3.3360e-01,  2.0593e-01]],\n",
       "\n",
       "        [[-4.9781e-02,  2.1438e-01,  1.5186e+00],\n",
       "         [ 4.7144e-01,  3.7590e-01,  4.0095e+00]],\n",
       "\n",
       "        [[ 1.9050e+00, -2.5966e-01, -2.4368e+00],\n",
       "         [-1.3846e+00,  2.2384e-01,  3.7427e+00]],\n",
       "\n",
       "        [[-6.0157e-01,  1.5416e-01, -2.7402e-02],\n",
       "         [-3.3994e-01, -2.0819e-01, -7.5072e-01]],\n",
       "\n",
       "        [[-1.3294e+00,  4.0922e-02,  2.9923e+00],\n",
       "         [ 1.0426e+00, -7.7505e-02,  2.6875e-01]],\n",
       "\n",
       "        [[ 1.6464e+00,  1.1901e-01, -2.4195e-02],\n",
       "         [-2.0334e+00, -8.7159e-02, -3.7490e-02]],\n",
       "\n",
       "        [[-1.2744e+00, -1.8381e+00, -1.1604e+00],\n",
       "         [-6.2351e-03, -1.6582e+00, -4.9559e-01]],\n",
       "\n",
       "        [[ 3.2784e-02, -9.5962e-01,  1.6404e-01],\n",
       "         [-8.0829e-01,  4.3769e-01, -7.0636e-02]],\n",
       "\n",
       "        [[ 1.4004e+00,  3.6632e-01, -1.0006e+00],\n",
       "         [-1.0082e+00, -2.2358e-01, -1.3529e+00]],\n",
       "\n",
       "        [[ 1.1778e-01, -1.3385e-01, -1.6550e-01],\n",
       "         [-5.8673e-01, -2.6509e-01,  1.0954e+00]],\n",
       "\n",
       "        [[-3.3666e-01,  8.8858e-01,  9.9927e-01],\n",
       "         [ 2.7078e-01,  2.1136e-01, -2.4136e-01]],\n",
       "\n",
       "        [[ 1.2104e-01,  1.2774e-01, -5.9867e-01],\n",
       "         [ 3.0489e-01, -1.1771e-01, -1.4425e+00]],\n",
       "\n",
       "        [[ 4.8298e-01,  1.6012e-01, -1.5696e-01],\n",
       "         [ 2.0378e-01, -4.9564e-02,  1.1339e+00]],\n",
       "\n",
       "        [[-7.2808e-01, -4.7709e-02,  6.2628e-01],\n",
       "         [ 7.2285e-02, -2.5918e-01,  3.6915e-01]],\n",
       "\n",
       "        [[ 2.6645e+00,  5.6140e-02,  1.2999e+00],\n",
       "         [ 2.1362e-01,  3.6065e-01,  1.1830e+00]],\n",
       "\n",
       "        [[ 1.5483e+00,  7.1224e-02,  9.2729e-01],\n",
       "         [-1.5122e+00, -2.2566e-01,  6.0477e-01]],\n",
       "\n",
       "        [[ 5.5298e-01,  3.0795e-02,  6.5480e-01],\n",
       "         [-1.6167e-01, -2.9309e-01,  6.4834e-01]],\n",
       "\n",
       "        [[ 1.4117e+00,  5.3386e-01, -7.2960e-01],\n",
       "         [ 4.8967e-02,  6.7998e-01,  2.0613e-01]],\n",
       "\n",
       "        [[-7.0796e-01, -6.7089e-02,  2.3024e-01],\n",
       "         [ 5.4159e-01,  1.6420e-02,  8.1020e-01]],\n",
       "\n",
       "        [[-1.1523e+01, -3.5396e+00, -1.5792e+01],\n",
       "         [-6.1555e-01, -1.2012e+00, -2.6084e+00]],\n",
       "\n",
       "        [[ 8.3812e-01,  1.8211e-01,  1.6210e+00],\n",
       "         [ 2.4720e-01, -2.5063e-01,  1.8065e+00]],\n",
       "\n",
       "        [[ 1.2879e+00, -3.4430e-01,  1.6532e+00],\n",
       "         [-1.9480e-01, -4.0229e-01,  1.7915e+00]],\n",
       "\n",
       "        [[-2.4530e+00, -3.4080e-01, -2.3945e-01],\n",
       "         [-1.2570e+00, -7.3059e-01, -1.2272e+00]],\n",
       "\n",
       "        [[ 9.7151e-01,  5.8850e-02,  1.6650e+00],\n",
       "         [ 2.7316e-01,  7.8860e-01, -4.3543e-01]],\n",
       "\n",
       "        [[-5.2891e-01, -8.0022e-01,  1.5190e+00],\n",
       "         [ 1.4894e+00,  8.8960e-02,  1.8415e+00]],\n",
       "\n",
       "        [[ 9.7336e-01, -2.0540e-01, -2.6407e+00],\n",
       "         [ 1.2199e+00, -3.8332e-01,  1.5576e+00]],\n",
       "\n",
       "        [[ 1.5787e+00,  7.4417e-01,  1.8077e+00],\n",
       "         [ 4.4008e-01,  3.9304e-01,  1.7640e+00]],\n",
       "\n",
       "        [[-1.4364e-01,  4.3858e-01,  7.0215e-02],\n",
       "         [ 1.6341e+00, -5.0604e-02,  7.2312e-01]],\n",
       "\n",
       "        [[ 1.1224e+00, -9.0719e-02,  7.1522e-01],\n",
       "         [ 6.0993e-01, -2.4264e-01,  1.6630e+00]],\n",
       "\n",
       "        [[ 8.8392e-01, -6.7955e-02, -1.7075e+00],\n",
       "         [ 1.9624e-01,  5.3518e-02, -5.8275e-01]],\n",
       "\n",
       "        [[ 2.7148e-01,  1.9207e-01,  7.9861e-01],\n",
       "         [ 8.1589e-01, -7.5642e-03,  5.0698e-01]],\n",
       "\n",
       "        [[ 2.9548e-01, -4.6356e-02, -1.1530e+00],\n",
       "         [ 1.2188e+00,  2.2241e-01, -1.0181e-01]],\n",
       "\n",
       "        [[-4.0940e-01,  3.2825e-01, -1.7857e+00],\n",
       "         [ 1.8230e+00,  9.2136e-01,  2.1684e-01]],\n",
       "\n",
       "        [[-1.6728e+00,  3.9181e-01, -2.3610e-01],\n",
       "         [ 1.3251e+00,  7.1772e-01,  5.5589e-02]],\n",
       "\n",
       "        [[-5.7986e-01,  1.1711e-01,  1.2629e+00],\n",
       "         [ 8.3606e-01,  8.1709e-02,  3.5985e-01]],\n",
       "\n",
       "        [[ 2.5274e-01,  5.0615e-01, -1.2215e+00],\n",
       "         [-1.0938e+00, -8.1938e-01, -1.5369e+00]],\n",
       "\n",
       "        [[ 1.2012e+00,  1.5922e-01, -1.1629e+00],\n",
       "         [ 1.0058e+00,  1.0523e-01, -3.5555e+00]]])"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "jac1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "geosink",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
