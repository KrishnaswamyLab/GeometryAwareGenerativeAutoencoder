{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Failed to detect the name of this notebook, you can set it manually with the WANDB_NOTEBOOK_NAME environment variable to enable code saving.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mxingzhis\u001b[0m. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n"
     ]
    }
   ],
   "source": [
    "import wandb\n",
    "import sys\n",
    "import matplotlib.pyplot as plt\n",
    "import scprep\n",
    "import pandas as pd\n",
    "sys.path.append('../src/')\n",
    "from evaluate import get_results\n",
    "from omegaconf import OmegaConf\n",
    "from main import load_data, make_model\n",
    "from model import AEDist\n",
    "import numpy as np\n",
    "import os\n",
    "import glob\n",
    "import demap\n",
    "from tqdm import tqdm\n",
    "# from evaluation import compute_encoding_metrics, get_dataset_contents, get_noiseless_name, get_ambient_name, get_data_config, eval_results, compute_recon_metric\n",
    "from evaluation import compute_all_metrics, get_noiseless_name, get_ambient_name, get_dataset_contents\n",
    "from transformations import NonTransform\n",
    "\n",
    "# Initialize wandb (replace 'your_entity' and 'your_project' with your specific details)\n",
    "wandb.login()\n",
    "api = wandb.Api()\n",
    "\n",
    "# Specify your entity, project, and sweep ID\n",
    "entity = \"xingzhis\"\n",
    "project = \"dmae\"\n",
    "sweep_id = 'nj0245gm'\n",
    "\n",
    "# Fetch the sweep\n",
    "sweep = api.sweep(f\"{entity}/{project}/{sweep_id}\")\n",
    "\n",
    "run_ids = [run.id for run in sweep.runs]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = np.load('../toy_data/converted/make_branch.npz')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['data_gt',\n",
       " 'colors',\n",
       " 'data',\n",
       " 'rotation_matrix',\n",
       " 'is_train',\n",
       " 'dist_all',\n",
       " 'dist',\n",
       " 'phate']"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/12 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/gpfs/gibbs/pi/krishnaswamy_smita/xingzhi/.conda_envs/geosink/lib/python3.11/site-packages/pytorch_lightning/utilities/parsing.py:269: UserWarning: Attribute 'activation_fn' is an instance of `nn.Module` and is already saved during checkpointing. It is recommended to ignore them using `self.save_hyperparameters(ignore=['activation_fn'])`.\n",
      "  rank_zero_warn(\n",
      "  8%|▊         | 1/12 [00:01<00:14,  1.29s/it]/gpfs/gibbs/pi/krishnaswamy_smita/xingzhi/.conda_envs/geosink/lib/python3.11/site-packages/pytorch_lightning/utilities/parsing.py:269: UserWarning: Attribute 'activation_fn' is an instance of `nn.Module` and is already saved during checkpointing. It is recommended to ignore them using `self.save_hyperparameters(ignore=['activation_fn'])`.\n",
      "  rank_zero_warn(\n",
      " 17%|█▋        | 2/12 [00:02<00:13,  1.35s/it]/gpfs/gibbs/pi/krishnaswamy_smita/xingzhi/.conda_envs/geosink/lib/python3.11/site-packages/pytorch_lightning/utilities/parsing.py:269: UserWarning: Attribute 'activation_fn' is an instance of `nn.Module` and is already saved during checkpointing. It is recommended to ignore them using `self.save_hyperparameters(ignore=['activation_fn'])`.\n",
      "  rank_zero_warn(\n",
      " 25%|██▌       | 3/12 [00:03<00:11,  1.24s/it]/gpfs/gibbs/pi/krishnaswamy_smita/xingzhi/.conda_envs/geosink/lib/python3.11/site-packages/pytorch_lightning/utilities/parsing.py:269: UserWarning: Attribute 'activation_fn' is an instance of `nn.Module` and is already saved during checkpointing. It is recommended to ignore them using `self.save_hyperparameters(ignore=['activation_fn'])`.\n",
      "  rank_zero_warn(\n",
      " 33%|███▎      | 4/12 [00:04<00:09,  1.20s/it]/gpfs/gibbs/pi/krishnaswamy_smita/xingzhi/.conda_envs/geosink/lib/python3.11/site-packages/pytorch_lightning/utilities/parsing.py:269: UserWarning: Attribute 'activation_fn' is an instance of `nn.Module` and is already saved during checkpointing. It is recommended to ignore them using `self.save_hyperparameters(ignore=['activation_fn'])`.\n",
      "  rank_zero_warn(\n",
      " 42%|████▏     | 5/12 [00:05<00:07,  1.12s/it]/gpfs/gibbs/pi/krishnaswamy_smita/xingzhi/.conda_envs/geosink/lib/python3.11/site-packages/pytorch_lightning/utilities/parsing.py:269: UserWarning: Attribute 'activation_fn' is an instance of `nn.Module` and is already saved during checkpointing. It is recommended to ignore them using `self.save_hyperparameters(ignore=['activation_fn'])`.\n",
      "  rank_zero_warn(\n",
      " 50%|█████     | 6/12 [00:06<00:06,  1.00s/it]/gpfs/gibbs/pi/krishnaswamy_smita/xingzhi/.conda_envs/geosink/lib/python3.11/site-packages/pytorch_lightning/utilities/parsing.py:269: UserWarning: Attribute 'activation_fn' is an instance of `nn.Module` and is already saved during checkpointing. It is recommended to ignore them using `self.save_hyperparameters(ignore=['activation_fn'])`.\n",
      "  rank_zero_warn(\n",
      " 58%|█████▊    | 7/12 [00:07<00:04,  1.17it/s]/gpfs/gibbs/pi/krishnaswamy_smita/xingzhi/.conda_envs/geosink/lib/python3.11/site-packages/pytorch_lightning/utilities/parsing.py:269: UserWarning: Attribute 'activation_fn' is an instance of `nn.Module` and is already saved during checkpointing. It is recommended to ignore them using `self.save_hyperparameters(ignore=['activation_fn'])`.\n",
      "  rank_zero_warn(\n",
      " 67%|██████▋   | 8/12 [00:07<00:02,  1.42it/s]/gpfs/gibbs/pi/krishnaswamy_smita/xingzhi/.conda_envs/geosink/lib/python3.11/site-packages/pytorch_lightning/utilities/parsing.py:269: UserWarning: Attribute 'activation_fn' is an instance of `nn.Module` and is already saved during checkpointing. It is recommended to ignore them using `self.save_hyperparameters(ignore=['activation_fn'])`.\n",
      "  rank_zero_warn(\n",
      " 75%|███████▌  | 9/12 [00:08<00:01,  1.52it/s]/gpfs/gibbs/pi/krishnaswamy_smita/xingzhi/.conda_envs/geosink/lib/python3.11/site-packages/pytorch_lightning/utilities/parsing.py:269: UserWarning: Attribute 'activation_fn' is an instance of `nn.Module` and is already saved during checkpointing. It is recommended to ignore them using `self.save_hyperparameters(ignore=['activation_fn'])`.\n",
      "  rank_zero_warn(\n",
      " 83%|████████▎ | 10/12 [00:08<00:01,  1.67it/s]/gpfs/gibbs/pi/krishnaswamy_smita/xingzhi/.conda_envs/geosink/lib/python3.11/site-packages/pytorch_lightning/utilities/parsing.py:269: UserWarning: Attribute 'activation_fn' is an instance of `nn.Module` and is already saved during checkpointing. It is recommended to ignore them using `self.save_hyperparameters(ignore=['activation_fn'])`.\n",
      "  rank_zero_warn(\n",
      " 92%|█████████▏| 11/12 [00:09<00:00,  1.53it/s]/gpfs/gibbs/pi/krishnaswamy_smita/xingzhi/.conda_envs/geosink/lib/python3.11/site-packages/pytorch_lightning/utilities/parsing.py:269: UserWarning: Attribute 'activation_fn' is an instance of `nn.Module` and is already saved during checkpointing. It is recommended to ignore them using `self.save_hyperparameters(ignore=['activation_fn'])`.\n",
      "  rank_zero_warn(\n",
      "100%|██████████| 12/12 [00:10<00:00,  1.19it/s]\n"
     ]
    }
   ],
   "source": [
    "results = []\n",
    "\n",
    "for i in tqdm(range(len(sweep.runs))):\n",
    "    run = sweep.runs[i]\n",
    "    cfg = OmegaConf.create(run.config)\n",
    "    folder_path = \"../src/wandb/\"\n",
    "    try:\n",
    "        folder_list = glob.glob(f\"{folder_path}*{run.id}*\")\n",
    "        ckpt_files = glob.glob(f\"{folder_list[0]}/files/*.ckpt\")\n",
    "        ckpt_path = ckpt_files[0]\n",
    "    except:\n",
    "        print(f\"No checkpoint found for run {run.id}\")\n",
    "    cfg = OmegaConf.create(run.config)\n",
    "    data_root = '../toy_data/converted/'\n",
    "    data_path = os.path.join(data_root, cfg.data.name + cfg.data.filetype)\n",
    "    noiseless_path = ''\n",
    "    # noiseless_path = os.path.join(data_root, get_noiseless_name(cfg.data.name) + cfg.data.filetype)\n",
    "    ambient_path = os.path.join(data_root, get_ambient_name(cfg.data.name) + '.npy')\n",
    "    pp = NonTransform()\n",
    "    emb_dim = cfg.model.emb_dim\n",
    "    dist_std = 1.\n",
    "    input_dim = 100\n",
    "    # model = make_model(cfg, input_dim, emb_dim, pp, dist_std, from_checkpoint=True, checkpoint_path=ckpt_path)\n",
    "    model = AEDist.load_from_checkpoint(ckpt_path)\n",
    "    res_dict = compute_all_metrics(model, data_path, noiseless_path, ambient_path, w_gt=True)\n",
    "    res_dict['dist_weight'] = cfg.model.dist_reconstr_weights\n",
    "    # results.append(res_dict)\n",
    "\n",
    "    data_noisy = np.load(data_path, allow_pickle=True)\n",
    "    X = data_noisy['data']\n",
    "    train_mask = data_noisy['is_train']\n",
    "    if 'dist' in data_noisy.files:\n",
    "        dist = data_noisy['dist']\n",
    "        dist_true=dist[~train_mask][:,~train_mask]\n",
    "    else:\n",
    "        dist_true=None\n",
    "    # data_noiseless = np.load(noiseless_path, allow_pickle=True)\n",
    "    # assert (train_mask == data_noiseless['is_train']).all()\n",
    "    # x_noiseless = data_noiseless['data'][~train_mask]\n",
    "    x_noiseless = data_noisy['data_gt'][~train_mask]\n",
    "    x_test=X[~train_mask]\n",
    "    x_phate = data_noisy['phate'][~train_mask]\n",
    "    demap_phate = demap.DEMaP(x_noiseless, x_phate)\n",
    "    res_dict['demap_phate'] = demap_phate\n",
    "\n",
    "    results.append(res_dict)\n",
    "\n",
    "\n",
    "res_df = pd.DataFrame(results)\n",
    "res_df.to_csv(\"toy_results.csv\", index=False)\n",
    "\n",
    "# res_df = res_df.sort_values(['seed', 'method', 'bcv', 'dropout'])\n",
    "# Round all numeric columns to 3 decimals, excluding strings\n",
    "rounded_res_df = res_df.select_dtypes(include=['float64']).round(3)\n",
    "# Re-attach the non-numeric columns to the rounded DataFrame\n",
    "for col in res_df.select_dtypes(exclude=['float64']).columns:\n",
    "    rounded_res_df[col] = res_df[col]\n",
    "\n",
    "# Reorder columns to match original DataFrame\n",
    "rounded_res_df = rounded_res_df[res_df.columns]\n",
    "rounded_res_df.to_csv(\"toy_results_rounded.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "res_df_filt = res_df[res_df['dist_weight'].apply(str) == '[0.9, 0.1, 0]'].drop(['accuracy', 'dist_weight', 'recon score'], axis=1)\n",
    "res_df_filt['data'] = res_df_filt['data'].apply(lambda x: x.split('/')[-1].split('.')[0][5:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>data</th>\n",
       "      <th>demap</th>\n",
       "      <th>demap_phate</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>sphere_branch</td>\n",
       "      <td>0.850682</td>\n",
       "      <td>0.850746</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>mix_surface</td>\n",
       "      <td>0.791811</td>\n",
       "      <td>0.789818</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>mix_density_surface</td>\n",
       "      <td>0.864376</td>\n",
       "      <td>0.864110</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>intersection</td>\n",
       "      <td>0.858100</td>\n",
       "      <td>0.849697</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>clusters</td>\n",
       "      <td>0.782918</td>\n",
       "      <td>0.780779</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>branch</td>\n",
       "      <td>0.883762</td>\n",
       "      <td>0.880847</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                   data     demap  demap_phate\n",
       "1         sphere_branch  0.850682     0.850746\n",
       "3           mix_surface  0.791811     0.789818\n",
       "4   mix_density_surface  0.864376     0.864110\n",
       "6          intersection  0.858100     0.849697\n",
       "8              clusters  0.782918     0.780779\n",
       "10               branch  0.883762     0.880847"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "res_df_filt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import wandb\n",
    "import sys\n",
    "import matplotlib.pyplot as plt\n",
    "import scprep\n",
    "import pandas as pd\n",
    "sys.path.append('../src/')\n",
    "from evaluate import get_results\n",
    "from omegaconf import OmegaConf\n",
    "import numpy as np\n",
    "import os\n",
    "import glob\n",
    "import demap\n",
    "from tqdm import tqdm\n",
    "from evaluation import compute_all_metrics, get_noiseless_name, get_ambient_name\n",
    "import torch\n",
    "from model import AEProb, Decoder\n",
    "\n",
    "class Model():\n",
    "    def __init__(self, encoder, decoder):\n",
    "        self.device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "        self.encoder = encoder.to(self.device)\n",
    "        self.decoder = decoder.to(self.device)\n",
    "    def encode(self, x):\n",
    "        return self.encoder.encode(x)\n",
    "    def decode(self, x):\n",
    "        return self.decoder(x)\n",
    "    def eval(self):\n",
    "        self.encoder.eval()\n",
    "        self.decoder.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "root_path = '/gpfs/gibbs/pi/krishnaswamy_smita/dl2282/dmae/results/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_paths = [\n",
    "    'sepa_gaussian_jsd_a1.0_knn5_branch_noise0.1_seed1',\n",
    "    'sepa_gaussian_jsd_a1.0_knn5_clusters_noise0.1_seed1',\n",
    "    'sepa_gaussian_jsd_a1.0_knn5_intersection_noise0.1_seed1',\n",
    "    'sepa_gaussian_jsd_a1.0_knn5_mix_density_surface_noise0.1_seed1',\n",
    "    'sepa_gaussian_jsd_a1.0_knn5_mix_surface_noise0.1_seed1',\n",
    "    'sepa_gaussian_jsd_a1.0_knn5_sphere_branch_noise0.1_seed1',\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/6 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 6/6 [00:03<00:00,  1.88it/s]\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "results = []\n",
    "for data_path1 in tqdm(data_paths):\n",
    "    if data_path1.startswith('sepa_'):\n",
    "        enc_path = os.path.join(root_path, data_path1, 'model.ckpt')\n",
    "        dec_path = os.path.join(root_path, data_path1, 'decoder.ckpt')\n",
    "        encoder_dict = torch.load(enc_path)\n",
    "        decoder_dict = torch.load(dec_path)\n",
    "        \n",
    "        # Regex pattern to extract the values\n",
    "        pattern = r\"sepa_(?P<prob_method>\\w+)_a(?P<alpha>[\\d.]+)_knn(?P<knn>\\d+)_(?P<noisy_path>.+)\"\n",
    "\n",
    "        # Perform regex search\n",
    "        match = re.search(pattern, data_path1)\n",
    "\n",
    "        if match:\n",
    "            # Extracting the values\n",
    "            prob_method = match.group(\"prob_method\")\n",
    "            alpha = match.group(\"alpha\")\n",
    "            knn = match.group(\"knn\")\n",
    "            noisy_path = match.group(\"noisy_path\")\n",
    "\n",
    "        data_name = noisy_path[:-15]\n",
    "        probmtd = prob_method\n",
    "        \n",
    "        data_root = '../toy_data/converted/'\n",
    "        data_path = os.path.join(data_root, 'make_' + data_name + '.npz')\n",
    "        noiseless_path = os.path.join(data_root, get_noiseless_name(data_name) + '.npz')\n",
    "        ambient_path = os.path.join(data_root, get_ambient_name(data_name) + '.npy')\n",
    "        encoder = AEProb(dim=100, emb_dim=2, layer_widths=[256, 128, 64], activation_fn=torch.nn.ReLU(), prob_method=probmtd, dist_reconstr_weights=[1.0,0.0,0.], )\n",
    "        encoder.load_state_dict(encoder_dict)\n",
    "        decoder = Decoder(dim=100, emb_dim=2, layer_widths=[256, 128, 64][::-1], activation_fn=torch.nn.ReLU())\n",
    "        decoder.load_state_dict(decoder_dict)\n",
    "        model = Model(encoder, decoder)\n",
    "        res_dict = compute_all_metrics(model, data_path, noiseless_path, ambient_path, w_gt=True)\n",
    "        res_dict['probmethod'] = probmtd\n",
    "        res_dict['alpha'] = alpha\n",
    "        res_dict['knn'] = knn\n",
    "        \n",
    "        results.append(res_dict)\n",
    "\n",
    "res_df_aff = pd.DataFrame(results)\n",
    "res_df_aff.to_csv(\"affinity_toy_results.csv\", index=False)\n",
    "\n",
    "# res_df_aff = res_df_aff.sort_values(['seedmethod', 'bcv', 'dropout', 'probmethod'])\n",
    "rounded_res_df_aff = res_df_aff.select_dtypes(include=['float64']).round(3)\n",
    "for col in res_df_aff.select_dtypes(exclude=['float64']).columns:\n",
    "    rounded_res_df_aff[col] = res_df_aff[col]\n",
    "\n",
    "rounded_res_df_aff = rounded_res_df_aff[res_df_aff.columns]\n",
    "rounded_res_df_aff.to_csv(\"affinity_toy_results_rounded.csv\", index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "res_df_aff_filt = res_df_aff.drop(['accuracy', 'recon score', 'probmethod', 'alpha', 'knn'], axis=1)\n",
    "res_df_aff_filt['data'] = res_df_aff_filt['data'].apply(lambda x: x.split('/')[-1].split('.')[0][5:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "res_df_aff_filt.rename(columns={'demap': 'Affi.'}, inplace=True)\n",
    "res_df_filt.rename(columns={'demap': 'Dist.', 'demap_phate': 'PHATE'}, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>data</th>\n",
       "      <th>Dist.</th>\n",
       "      <th>PHATE</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>sphere_branch</td>\n",
       "      <td>0.850682</td>\n",
       "      <td>0.850746</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>mix_surface</td>\n",
       "      <td>0.791811</td>\n",
       "      <td>0.789818</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>mix_density_surface</td>\n",
       "      <td>0.864376</td>\n",
       "      <td>0.864110</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>intersection</td>\n",
       "      <td>0.858100</td>\n",
       "      <td>0.849697</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>clusters</td>\n",
       "      <td>0.782918</td>\n",
       "      <td>0.780779</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>branch</td>\n",
       "      <td>0.883762</td>\n",
       "      <td>0.880847</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                   data     Dist.     PHATE\n",
       "1         sphere_branch  0.850682  0.850746\n",
       "3           mix_surface  0.791811  0.789818\n",
       "4   mix_density_surface  0.864376  0.864110\n",
       "6          intersection  0.858100  0.849697\n",
       "8              clusters  0.782918  0.780779\n",
       "10               branch  0.883762  0.880847"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "res_df_filt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>data</th>\n",
       "      <th>Affi.</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>branch</td>\n",
       "      <td>0.900757</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>clusters</td>\n",
       "      <td>0.798298</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>intersection</td>\n",
       "      <td>0.733879</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>mix_density_surface</td>\n",
       "      <td>0.843479</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>mix_surface</td>\n",
       "      <td>0.816707</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>sphere_branch</td>\n",
       "      <td>0.869579</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                  data     Affi.\n",
       "0               branch  0.900757\n",
       "1             clusters  0.798298\n",
       "2         intersection  0.733879\n",
       "3  mix_density_surface  0.843479\n",
       "4          mix_surface  0.816707\n",
       "5        sphere_branch  0.869579"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "res_df_aff_filt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "merged_df = res_df_filt.merge(res_df_aff_filt, on='data')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "merged_df.iloc[:, 1:] = merged_df.iloc[:, 1:].apply(lambda x: x.round(3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "column_order = ['data', 'Affi.', 'Dist.', 'PHATE']\n",
    "merged_df = merged_df.reindex(columns=column_order)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "geosink",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
