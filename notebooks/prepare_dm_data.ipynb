{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "import wandb\n",
    "import sys\n",
    "import matplotlib.pyplot as plt\n",
    "import scprep\n",
    "import pandas as pd\n",
    "sys.path.append('../src/')\n",
    "from evaluate import get_results\n",
    "from omegaconf import OmegaConf\n",
    "from main import load_data\n",
    "from model import AEDist\n",
    "import numpy as np\n",
    "import os\n",
    "import glob\n",
    "import torch\n",
    "\n",
    "def prepare_dm_data(cfg, save_path='../dm_data/', folder_path=\"../src/wandb/\"):\n",
    "    folder_list = glob.glob(f\"{folder_path}*{run.id}*\")\n",
    "    ckpt_files = glob.glob(f\"{folder_list[0]}/files/*.ckpt\")\n",
    "    ckpt_path = ckpt_files[0]\n",
    "    data_path = os.path.join(cfg.data.root, cfg.data.name + cfg.data.filetype)\n",
    "    data = np.load(data_path, allow_pickle=True)\n",
    "    # model = AEDist(dim=50, emb_dim=10)\n",
    "    # model.load_from_checkpoint(ckpt_path)\n",
    "    model = AEDist.load_from_checkpoint(ckpt_path)\n",
    "    model.eval()\n",
    "    x_all = torch.tensor(data['data'], dtype=torch.float32)\n",
    "    x_pred, z_pred = model(x_all)\n",
    "    x_pred = x_pred.detach().cpu().numpy()\n",
    "    z_pred = z_pred.detach().cpu().numpy()\n",
    "    save_name = f'{save_path}/{cfg.data.name}_{cfg.model.emb_dim}_dm.npz'\n",
    "    np.savez(save_name, data=z_pred, train_mask=data['is_train'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "wandb.login()\n",
    "api = wandb.Api()\n",
    "\n",
    "# Specify your entity, project, and sweep ID\n",
    "entity = \"xingzhis\"\n",
    "project = \"dmae\"\n",
    "sweep_id = 'j7tcyoop'\n",
    "\n",
    "# Fetch the sweep\n",
    "sweep = api.sweep(f\"{entity}/{project}/{sweep_id}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize an empty list to store run data\n",
    "runs_data = []\n",
    "\n",
    "# Iterate through each run in the sweep\n",
    "for run in sweep.runs:\n",
    "    # Extract metrics and configs\n",
    "    metrics = run.summary._json_dict\n",
    "    configs = run.config\n",
    "    \n",
    "    # Combine metrics and configs, and add run ID\n",
    "    combined_data = {**metrics, **configs, \"run_id\": run.id}\n",
    "    \n",
    "    # Append the combined data to the list\n",
    "    runs_data.append(combined_data)\n",
    "\n",
    "# Create a DataFrame from the runs data\n",
    "df = pd.DataFrame(runs_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/gpfs/gibbs/pi/krishnaswamy_smita/xingzhi/dmae/notebooks/../src/model.py:281: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  self.register_buffer('mean', torch.tensor(mean, dtype=torch.float32), persistent=True)\n",
      "/gpfs/gibbs/pi/krishnaswamy_smita/xingzhi/dmae/notebooks/../src/model.py:282: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  self.register_buffer('std', torch.tensor(std, dtype=torch.float32), persistent=True)\n",
      "/gpfs/gibbs/pi/krishnaswamy_smita/xingzhi/.conda_envs/geosink/lib/python3.11/site-packages/pytorch_lightning/utilities/parsing.py:269: UserWarning: Attribute 'activation_fn' is an instance of `nn.Module` and is already saved during checkpointing. It is recommended to ignore them using `self.save_hyperparameters(ignore=['activation_fn'])`.\n",
      "  rank_zero_warn(\n",
      "/gpfs/gibbs/pi/krishnaswamy_smita/xingzhi/dmae/notebooks/../src/model.py:281: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  self.register_buffer('mean', torch.tensor(mean, dtype=torch.float32), persistent=True)\n",
      "/gpfs/gibbs/pi/krishnaswamy_smita/xingzhi/dmae/notebooks/../src/model.py:282: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  self.register_buffer('std', torch.tensor(std, dtype=torch.float32), persistent=True)\n",
      "/gpfs/gibbs/pi/krishnaswamy_smita/xingzhi/.conda_envs/geosink/lib/python3.11/site-packages/pytorch_lightning/utilities/parsing.py:269: UserWarning: Attribute 'activation_fn' is an instance of `nn.Module` and is already saved during checkpointing. It is recommended to ignore them using `self.save_hyperparameters(ignore=['activation_fn'])`.\n",
      "  rank_zero_warn(\n",
      "/gpfs/gibbs/pi/krishnaswamy_smita/xingzhi/dmae/notebooks/../src/model.py:281: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  self.register_buffer('mean', torch.tensor(mean, dtype=torch.float32), persistent=True)\n",
      "/gpfs/gibbs/pi/krishnaswamy_smita/xingzhi/dmae/notebooks/../src/model.py:282: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  self.register_buffer('std', torch.tensor(std, dtype=torch.float32), persistent=True)\n",
      "/gpfs/gibbs/pi/krishnaswamy_smita/xingzhi/.conda_envs/geosink/lib/python3.11/site-packages/pytorch_lightning/utilities/parsing.py:269: UserWarning: Attribute 'activation_fn' is an instance of `nn.Module` and is already saved during checkpointing. It is recommended to ignore them using `self.save_hyperparameters(ignore=['activation_fn'])`.\n",
      "  rank_zero_warn(\n",
      "/gpfs/gibbs/pi/krishnaswamy_smita/xingzhi/dmae/notebooks/../src/model.py:281: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  self.register_buffer('mean', torch.tensor(mean, dtype=torch.float32), persistent=True)\n",
      "/gpfs/gibbs/pi/krishnaswamy_smita/xingzhi/dmae/notebooks/../src/model.py:282: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  self.register_buffer('std', torch.tensor(std, dtype=torch.float32), persistent=True)\n",
      "/gpfs/gibbs/pi/krishnaswamy_smita/xingzhi/.conda_envs/geosink/lib/python3.11/site-packages/pytorch_lightning/utilities/parsing.py:269: UserWarning: Attribute 'activation_fn' is an instance of `nn.Module` and is already saved during checkpointing. It is recommended to ignore them using `self.save_hyperparameters(ignore=['activation_fn'])`.\n",
      "  rank_zero_warn(\n",
      "/gpfs/gibbs/pi/krishnaswamy_smita/xingzhi/dmae/notebooks/../src/model.py:281: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  self.register_buffer('mean', torch.tensor(mean, dtype=torch.float32), persistent=True)\n",
      "/gpfs/gibbs/pi/krishnaswamy_smita/xingzhi/dmae/notebooks/../src/model.py:282: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  self.register_buffer('std', torch.tensor(std, dtype=torch.float32), persistent=True)\n",
      "/gpfs/gibbs/pi/krishnaswamy_smita/xingzhi/.conda_envs/geosink/lib/python3.11/site-packages/pytorch_lightning/utilities/parsing.py:269: UserWarning: Attribute 'activation_fn' is an instance of `nn.Module` and is already saved during checkpointing. It is recommended to ignore them using `self.save_hyperparameters(ignore=['activation_fn'])`.\n",
      "  rank_zero_warn(\n",
      "/gpfs/gibbs/pi/krishnaswamy_smita/xingzhi/dmae/notebooks/../src/model.py:281: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  self.register_buffer('mean', torch.tensor(mean, dtype=torch.float32), persistent=True)\n",
      "/gpfs/gibbs/pi/krishnaswamy_smita/xingzhi/dmae/notebooks/../src/model.py:282: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  self.register_buffer('std', torch.tensor(std, dtype=torch.float32), persistent=True)\n",
      "/gpfs/gibbs/pi/krishnaswamy_smita/xingzhi/.conda_envs/geosink/lib/python3.11/site-packages/pytorch_lightning/utilities/parsing.py:269: UserWarning: Attribute 'activation_fn' is an instance of `nn.Module` and is already saved during checkpointing. It is recommended to ignore them using `self.save_hyperparameters(ignore=['activation_fn'])`.\n",
      "  rank_zero_warn(\n",
      "/gpfs/gibbs/pi/krishnaswamy_smita/xingzhi/dmae/notebooks/../src/model.py:281: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  self.register_buffer('mean', torch.tensor(mean, dtype=torch.float32), persistent=True)\n",
      "/gpfs/gibbs/pi/krishnaswamy_smita/xingzhi/dmae/notebooks/../src/model.py:282: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  self.register_buffer('std', torch.tensor(std, dtype=torch.float32), persistent=True)\n",
      "/gpfs/gibbs/pi/krishnaswamy_smita/xingzhi/.conda_envs/geosink/lib/python3.11/site-packages/pytorch_lightning/utilities/parsing.py:269: UserWarning: Attribute 'activation_fn' is an instance of `nn.Module` and is already saved during checkpointing. It is recommended to ignore them using `self.save_hyperparameters(ignore=['activation_fn'])`.\n",
      "  rank_zero_warn(\n",
      "/gpfs/gibbs/pi/krishnaswamy_smita/xingzhi/dmae/notebooks/../src/model.py:281: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  self.register_buffer('mean', torch.tensor(mean, dtype=torch.float32), persistent=True)\n",
      "/gpfs/gibbs/pi/krishnaswamy_smita/xingzhi/dmae/notebooks/../src/model.py:282: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  self.register_buffer('std', torch.tensor(std, dtype=torch.float32), persistent=True)\n",
      "/gpfs/gibbs/pi/krishnaswamy_smita/xingzhi/.conda_envs/geosink/lib/python3.11/site-packages/pytorch_lightning/utilities/parsing.py:269: UserWarning: Attribute 'activation_fn' is an instance of `nn.Module` and is already saved during checkpointing. It is recommended to ignore them using `self.save_hyperparameters(ignore=['activation_fn'])`.\n",
      "  rank_zero_warn(\n",
      "/gpfs/gibbs/pi/krishnaswamy_smita/xingzhi/dmae/notebooks/../src/model.py:281: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  self.register_buffer('mean', torch.tensor(mean, dtype=torch.float32), persistent=True)\n",
      "/gpfs/gibbs/pi/krishnaswamy_smita/xingzhi/dmae/notebooks/../src/model.py:282: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  self.register_buffer('std', torch.tensor(std, dtype=torch.float32), persistent=True)\n",
      "/gpfs/gibbs/pi/krishnaswamy_smita/xingzhi/.conda_envs/geosink/lib/python3.11/site-packages/pytorch_lightning/utilities/parsing.py:269: UserWarning: Attribute 'activation_fn' is an instance of `nn.Module` and is already saved during checkpointing. It is recommended to ignore them using `self.save_hyperparameters(ignore=['activation_fn'])`.\n",
      "  rank_zero_warn(\n",
      "/gpfs/gibbs/pi/krishnaswamy_smita/xingzhi/dmae/notebooks/../src/model.py:281: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  self.register_buffer('mean', torch.tensor(mean, dtype=torch.float32), persistent=True)\n",
      "/gpfs/gibbs/pi/krishnaswamy_smita/xingzhi/dmae/notebooks/../src/model.py:282: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  self.register_buffer('std', torch.tensor(std, dtype=torch.float32), persistent=True)\n",
      "/gpfs/gibbs/pi/krishnaswamy_smita/xingzhi/.conda_envs/geosink/lib/python3.11/site-packages/pytorch_lightning/utilities/parsing.py:269: UserWarning: Attribute 'activation_fn' is an instance of `nn.Module` and is already saved during checkpointing. It is recommended to ignore them using `self.save_hyperparameters(ignore=['activation_fn'])`.\n",
      "  rank_zero_warn(\n"
     ]
    }
   ],
   "source": [
    "dims = df['emb_dim'].unique()\n",
    "data_names = df['data.name'].unique()\n",
    "dfs = []\n",
    "for dim in dims:\n",
    "    for data_name in data_names:\n",
    "        ids = df[(df['data.name'] == data_name) & (df['emb_dim'] == dim)].sort_values(by=['validation/reconstr_loss', 'validation/dist_accuracy'], ascending=[True, False]).iloc[0,:][['data.name', 'emb_dim', 'validation/reconstr_loss', 'validation/dist_accuracy', 'run_id']]\n",
    "        run_id = ids['run_id']\n",
    "        run = [run for run in sweep.runs if run.id == run_id][0]\n",
    "        cfg = OmegaConf.create(run.config)\n",
    "        prepare_dm_data(cfg)\n",
    "        dfs.append(ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'pd' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[1], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m df_name \u001b[39m=\u001b[39m pd\u001b[39m.\u001b[39mconcat(dfs, axis\u001b[39m=\u001b[39m\u001b[39m1\u001b[39m)\u001b[39m.\u001b[39mT\u001b[39m.\u001b[39msort_values([\u001b[39m'\u001b[39m\u001b[39mdata.name\u001b[39m\u001b[39m'\u001b[39m, \u001b[39m'\u001b[39m\u001b[39memb_dim\u001b[39m\u001b[39m'\u001b[39m])\n\u001b[1;32m      2\u001b[0m df_name\u001b[39m.\u001b[39mto_csv(\u001b[39m'\u001b[39m\u001b[39m../dm_data/differnt_dims.csv\u001b[39m\u001b[39m'\u001b[39m, index\u001b[39m=\u001b[39m\u001b[39mFalse\u001b[39;00m)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'pd' is not defined"
     ]
    }
   ],
   "source": [
    "df_name = pd.concat(dfs, axis=1).T.sort_values(['data.name', 'emb_dim'])\n",
    "df_name.to_csv('../dm_data/differnt_dims.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_name['sweep'] = sweep_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>data.name</th>\n",
       "      <th>emb_dim</th>\n",
       "      <th>validation/reconstr_loss</th>\n",
       "      <th>validation/dist_accuracy</th>\n",
       "      <th>run_id</th>\n",
       "      <th>sweep</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>eb_subset_all</td>\n",
       "      <td>5</td>\n",
       "      <td>1.428262</td>\n",
       "      <td>0.866203</td>\n",
       "      <td>9xtkqnkl</td>\n",
       "      <td>j7tcyoop</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>eb_subset_all</td>\n",
       "      <td>15</td>\n",
       "      <td>1.31582</td>\n",
       "      <td>0.867569</td>\n",
       "      <td>u98snjwi</td>\n",
       "      <td>j7tcyoop</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>eb_subset_all</td>\n",
       "      <td>20</td>\n",
       "      <td>1.294534</td>\n",
       "      <td>0.879244</td>\n",
       "      <td>9sapq4h8</td>\n",
       "      <td>j7tcyoop</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>eb_subset_all</td>\n",
       "      <td>25</td>\n",
       "      <td>1.277464</td>\n",
       "      <td>0.875017</td>\n",
       "      <td>m07wclny</td>\n",
       "      <td>j7tcyoop</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>eb_subset_all</td>\n",
       "      <td>30</td>\n",
       "      <td>1.27806</td>\n",
       "      <td>0.880826</td>\n",
       "      <td>p14vurq1</td>\n",
       "      <td>j7tcyoop</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>74</th>\n",
       "      <td>sea_ad_gaba_all</td>\n",
       "      <td>5</td>\n",
       "      <td>0.657298</td>\n",
       "      <td>0.918041</td>\n",
       "      <td>najohsy0</td>\n",
       "      <td>j7tcyoop</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>56</th>\n",
       "      <td>sea_ad_gaba_all</td>\n",
       "      <td>15</td>\n",
       "      <td>0.638394</td>\n",
       "      <td>0.927088</td>\n",
       "      <td>m2874yfn</td>\n",
       "      <td>j7tcyoop</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>78</th>\n",
       "      <td>sea_ad_gaba_all</td>\n",
       "      <td>20</td>\n",
       "      <td>0.639052</td>\n",
       "      <td>0.937962</td>\n",
       "      <td>4se1cs5d</td>\n",
       "      <td>j7tcyoop</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>52</th>\n",
       "      <td>sea_ad_gaba_all</td>\n",
       "      <td>25</td>\n",
       "      <td>0.626545</td>\n",
       "      <td>0.937596</td>\n",
       "      <td>islnpqz2</td>\n",
       "      <td>j7tcyoop</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>71</th>\n",
       "      <td>sea_ad_gaba_all</td>\n",
       "      <td>30</td>\n",
       "      <td>0.647009</td>\n",
       "      <td>0.932049</td>\n",
       "      <td>cbgj4rf2</td>\n",
       "      <td>j7tcyoop</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          data.name emb_dim validation/reconstr_loss validation/dist_accuracy  \\\n",
       "28    eb_subset_all       5                 1.428262                 0.866203   \n",
       "27    eb_subset_all      15                  1.31582                 0.867569   \n",
       "25    eb_subset_all      20                 1.294534                 0.879244   \n",
       "3     eb_subset_all      25                 1.277464                 0.875017   \n",
       "16    eb_subset_all      30                  1.27806                 0.880826   \n",
       "74  sea_ad_gaba_all       5                 0.657298                 0.918041   \n",
       "56  sea_ad_gaba_all      15                 0.638394                 0.927088   \n",
       "78  sea_ad_gaba_all      20                 0.639052                 0.937962   \n",
       "52  sea_ad_gaba_all      25                 0.626545                 0.937596   \n",
       "71  sea_ad_gaba_all      30                 0.647009                 0.932049   \n",
       "\n",
       "      run_id     sweep  \n",
       "28  9xtkqnkl  j7tcyoop  \n",
       "27  u98snjwi  j7tcyoop  \n",
       "25  9sapq4h8  j7tcyoop  \n",
       "3   m07wclny  j7tcyoop  \n",
       "16  p14vurq1  j7tcyoop  \n",
       "74  najohsy0  j7tcyoop  \n",
       "56  m2874yfn  j7tcyoop  \n",
       "78  4se1cs5d  j7tcyoop  \n",
       "52  islnpqz2  j7tcyoop  \n",
       "71  cbgj4rf2  j7tcyoop  "
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "geosink",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
