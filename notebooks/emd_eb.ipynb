{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import wandb\n",
    "import sys\n",
    "import matplotlib.pyplot as plt\n",
    "import scprep\n",
    "import pandas as pd\n",
    "sys.path.append('../src/')\n",
    "from diffusion import DiffusionModel\n",
    "from evaluate import get_results\n",
    "from omegaconf import OmegaConf\n",
    "from main import load_data, make_model\n",
    "import numpy as np\n",
    "import os\n",
    "import glob\n",
    "import matplotlib.animation as animation\n",
    "from matplotlib.animation import PillowWriter\n",
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "AEDist.__init__() missing 2 required positional arguments: 'dim' and 'emb_dim'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[6], line 28\u001b[0m\n\u001b[1;32m     26\u001b[0m data \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39mload(data_path, allow_pickle\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m)\n\u001b[1;32m     27\u001b[0m dist_std \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39mstd(data[\u001b[39m'\u001b[39m\u001b[39mdist\u001b[39m\u001b[39m'\u001b[39m]\u001b[39m.\u001b[39mflatten())\n\u001b[0;32m---> 28\u001b[0m model \u001b[39m=\u001b[39m make_model(cfg, X\u001b[39m.\u001b[39mshape[\u001b[39m1\u001b[39m], emb_dim, pp, dist_std, \u001b[39mNone\u001b[39;00m, \u001b[39mNone\u001b[39;00m, from_checkpoint\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m, checkpoint_path\u001b[39m=\u001b[39mckpt_path)\n\u001b[1;32m     29\u001b[0m model\u001b[39m.\u001b[39meval()\n\u001b[1;32m     30\u001b[0m \u001b[39m# x_all = next(iter(allloader))['x']\u001b[39;00m\n",
      "File \u001b[0;32m/gpfs/gibbs/pi/krishnaswamy_smita/xingzhi/dmae/notebooks/../src/main.py:226\u001b[0m, in \u001b[0;36mmake_model\u001b[0;34m(cfg, dim, emb_dim, pp, dist_std, mean, std, from_checkpoint, checkpoint_path)\u001b[0m\n\u001b[1;32m    224\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mmake_model\u001b[39m(cfg, dim, emb_dim, pp, dist_std, mean, std, from_checkpoint\u001b[39m=\u001b[39m\u001b[39mFalse\u001b[39;00m, checkpoint_path\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m):\n\u001b[1;32m    225\u001b[0m     \u001b[39mif\u001b[39;00m from_checkpoint:\n\u001b[0;32m--> 226\u001b[0m         \u001b[39mreturn\u001b[39;00m AEDist\u001b[39m.\u001b[39mload_from_checkpoint(checkpoint_path)\n\u001b[1;32m    227\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39m'\u001b[39m\u001b[39memb_dim\u001b[39m\u001b[39m'\u001b[39m \u001b[39min\u001b[39;00m cfg\u001b[39m.\u001b[39mmodel:\n\u001b[1;32m    228\u001b[0m         emb_dim \u001b[39m=\u001b[39m cfg\u001b[39m.\u001b[39mmodel\u001b[39m.\u001b[39memb_dim\n",
      "File \u001b[0;32m/gpfs/gibbs/pi/krishnaswamy_smita/xingzhi/.conda_envs/geosink/lib/python3.11/site-packages/pytorch_lightning/core/saving.py:139\u001b[0m, in \u001b[0;36mModelIO.load_from_checkpoint\u001b[0;34m(cls, checkpoint_path, map_location, hparams_file, strict, **kwargs)\u001b[0m\n\u001b[1;32m     59\u001b[0m \u001b[39m@classmethod\u001b[39m\n\u001b[1;32m     60\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mload_from_checkpoint\u001b[39m(\n\u001b[1;32m     61\u001b[0m     \u001b[39mcls\u001b[39m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     66\u001b[0m     \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs: Any,\n\u001b[1;32m     67\u001b[0m ) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m Self:\n\u001b[1;32m     68\u001b[0m \u001b[39m    \u001b[39m\u001b[39mr\u001b[39m\u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m     69\u001b[0m \u001b[39m    Primary way of loading a model from a checkpoint. When Lightning saves a checkpoint\u001b[39;00m\n\u001b[1;32m     70\u001b[0m \u001b[39m    it stores the arguments passed to ``__init__``  in the checkpoint under ``\"hyper_parameters\"``.\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    137\u001b[0m \u001b[39m        y_hat = pretrained_model(x)\u001b[39;00m\n\u001b[1;32m    138\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 139\u001b[0m     \u001b[39mreturn\u001b[39;00m _load_from_checkpoint(  \u001b[39m# type: ignore[return-value]\u001b[39;00m\n\u001b[1;32m    140\u001b[0m         \u001b[39mcls\u001b[39m,\n\u001b[1;32m    141\u001b[0m         checkpoint_path,\n\u001b[1;32m    142\u001b[0m         map_location,\n\u001b[1;32m    143\u001b[0m         hparams_file,\n\u001b[1;32m    144\u001b[0m         strict,\n\u001b[1;32m    145\u001b[0m         \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs,\n\u001b[1;32m    146\u001b[0m     )\n",
      "File \u001b[0;32m/gpfs/gibbs/pi/krishnaswamy_smita/xingzhi/.conda_envs/geosink/lib/python3.11/site-packages/pytorch_lightning/core/saving.py:188\u001b[0m, in \u001b[0;36m_load_from_checkpoint\u001b[0;34m(cls, checkpoint_path, map_location, hparams_file, strict, **kwargs)\u001b[0m\n\u001b[1;32m    186\u001b[0m     \u001b[39mreturn\u001b[39;00m _load_state(\u001b[39mcls\u001b[39m, checkpoint, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[1;32m    187\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39missubclass\u001b[39m(\u001b[39mcls\u001b[39m, pl\u001b[39m.\u001b[39mLightningModule):\n\u001b[0;32m--> 188\u001b[0m     \u001b[39mreturn\u001b[39;00m _load_state(\u001b[39mcls\u001b[39m, checkpoint, strict\u001b[39m=\u001b[39mstrict, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[1;32m    189\u001b[0m \u001b[39mraise\u001b[39;00m \u001b[39mNotImplementedError\u001b[39;00m(\u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mUnsupported \u001b[39m\u001b[39m{\u001b[39;00m\u001b[39mcls\u001b[39m\u001b[39m}\u001b[39;00m\u001b[39m\"\u001b[39m)\n",
      "File \u001b[0;32m/gpfs/gibbs/pi/krishnaswamy_smita/xingzhi/.conda_envs/geosink/lib/python3.11/site-packages/pytorch_lightning/core/saving.py:234\u001b[0m, in \u001b[0;36m_load_state\u001b[0;34m(cls, checkpoint, strict, **cls_kwargs_new)\u001b[0m\n\u001b[1;32m    230\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m cls_spec\u001b[39m.\u001b[39mvarkw:\n\u001b[1;32m    231\u001b[0m     \u001b[39m# filter kwargs according to class init unless it allows any argument via kwargs\u001b[39;00m\n\u001b[1;32m    232\u001b[0m     _cls_kwargs \u001b[39m=\u001b[39m {k: v \u001b[39mfor\u001b[39;00m k, v \u001b[39min\u001b[39;00m _cls_kwargs\u001b[39m.\u001b[39mitems() \u001b[39mif\u001b[39;00m k \u001b[39min\u001b[39;00m cls_init_args_name}\n\u001b[0;32m--> 234\u001b[0m obj \u001b[39m=\u001b[39m \u001b[39mcls\u001b[39m(\u001b[39m*\u001b[39m\u001b[39m*\u001b[39m_cls_kwargs)\n\u001b[1;32m    236\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39misinstance\u001b[39m(obj, pl\u001b[39m.\u001b[39mLightningModule):\n\u001b[1;32m    237\u001b[0m     \u001b[39m# give model a chance to load something\u001b[39;00m\n\u001b[1;32m    238\u001b[0m     obj\u001b[39m.\u001b[39mon_load_checkpoint(checkpoint)\n",
      "\u001b[0;31mTypeError\u001b[0m: AEDist.__init__() missing 2 required positional arguments: 'dim' and 'emb_dim'"
     ]
    }
   ],
   "source": [
    "# Initialize wandb (replace 'your_entity' and 'your_project' with your specific details)\n",
    "import torch\n",
    "wandb.login()\n",
    "api = wandb.Api()\n",
    "\n",
    "# Specify your entity, project, and sweep ID\n",
    "entity = \"xingzhis\"\n",
    "project = \"dmae\"\n",
    "sweep_id = 'n7krfbsz'\n",
    "\n",
    "# Fetch the sweep\n",
    "sweep = api.sweep(f\"{entity}/{project}/{sweep_id}\")\n",
    "\n",
    "run_ids = [run.id for run in sweep.runs]\n",
    "run_id = 'ucvq4x2o'\n",
    "run = [run for run in sweep.runs if run.id == run_id][0]\n",
    "\n",
    "cfg = OmegaConf.create(run.config)\n",
    "folder_path = \"../src/wandb/\"\n",
    "folder_list = glob.glob(f\"{folder_path}*{run.id}*\")\n",
    "ckpt_files = glob.glob(f\"{folder_list[0]}/files/*.ckpt\")\n",
    "ckpt_path = ckpt_files[0]\n",
    "allloader, _, X, phate_coords, colors, dist, pp, _, _ = load_data(cfg, load_all=False)\n",
    "emb_dim = phate_coords.shape[1]\n",
    "data_path = os.path.join(cfg.data.root, cfg.data.name + cfg.data.filetype)\n",
    "data = np.load(data_path, allow_pickle=True)\n",
    "dist_std = np.std(data['dist'].flatten())\n",
    "model = make_model(cfg, X.shape[1], emb_dim, pp, dist_std, from_checkpoint=True, checkpoint_path=ckpt_path)\n",
    "model.eval()\n",
    "x_all = next(iter(allloader))['x']\n",
    "x_pred, z_pred = model(x_all)\n",
    "x_pred = x_pred.detach().cpu().numpy()\n",
    "z_pred = z_pred.detach().cpu().numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize wandb (replace 'your_entity' and 'your_project' with your specific details)\n",
    "wandb.login()\n",
    "api = wandb.Api()\n",
    "\n",
    "# Specify your entity, project, and sweep ID\n",
    "entity = \"xingzhis\"\n",
    "project = \"dmae\"\n",
    "sweep_id = 'u05futg7'\n",
    "\n",
    "# Fetch the sweep\n",
    "sweep = api.sweep(f\"{entity}/{project}/{sweep_id}\")\n",
    "\n",
    "run_ids = [run.id for run in sweep.runs]\n",
    "\n",
    "run_id = 'xsj3odwl'\n",
    "run = [run for run in sweep.runs if run.id == run_id][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cfg = OmegaConf.create(run.config)\n",
    "folder_path = \"../src/wandb/\"\n",
    "folder_list = glob.glob(f\"{folder_path}*{run.id}*\")\n",
    "ckpt_files = glob.glob(f\"{folder_list[0]}/files/*.ckpt\")\n",
    "ckpt_path = ckpt_files[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/gpfs/gibbs/pi/krishnaswamy_smita/xingzhi/.conda_envs/geosink/lib/python3.11/site-packages/pytorch_lightning/utilities/parsing.py:269: UserWarning: Attribute 'activation_fn' is an instance of `nn.Module` and is already saved during checkpointing. It is recommended to ignore them using `self.save_hyperparameters(ignore=['activation_fn'])`.\n",
      "  rank_zero_warn(\n"
     ]
    }
   ],
   "source": [
    "diffusionmodel = DiffusionModel.load_from_checkpoint(\n",
    "    checkpoint_path=ckpt_path,\n",
    "    data_size=10, \n",
    "    time_embedding_size=cfg.time_embedding_size,\n",
    "    layer_widths=cfg.layer_widths,\n",
    "    dropout=cfg.dropout,\n",
    "    batch_norm=cfg.batch_norm,\n",
    "    num_steps=cfg.num_steps,\n",
    "    learning_rate=cfg.lr,\n",
    "    weight_decay=cfg.weight_decay,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_mask = data['is_train']\n",
    "data_train = data['data'][train_mask]\n",
    "color_train = data['colors'][train_mask]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_pred = x_pred[~train_mask]\n",
    "latent_pred = z_pred[~train_mask]\n",
    "with torch.no_grad():\n",
    "    generated_latent = diffusionmodel.generate_samples((~train_mask).sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_latent = np.load(cfg.path + cfg.data)\n",
    "data_latent_train = data_latent['data'][data_latent['train_mask']]\n",
    "mean_, std_ = np.mean(data_latent_train, axis=0), np.std(data_latent_train, axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "generated_latent = generated_latent * std_ + mean_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with torch.no_grad():\n",
    "    generated_ambient = model.decode(generated_latent)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "generated = generated_ambient.detach().cpu().numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pylab as pl\n",
    "import ot\n",
    "import ot.plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "latent_gen = generated_latent.detach().cpu().numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "latent_test = data_latent['data'][~data_latent['train_mask']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "M = ot.dist(latent_gen, latent_test)\n",
    "M = torch.tensor(M, dtype=torch.float32, device=device)\n",
    "M/=M.max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n = latent_test.shape[0]\n",
    "a, b = torch.ones((n,)).to(device) / n, torch.ones((n,)).to(device) / n  # uniform distribution on samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/gpfs/gibbs/pi/krishnaswamy_smita/xingzhi/.conda_envs/geosink/lib/python3.11/site-packages/ot/lp/__init__.py:354: UserWarning: numItermax reached before optimality. Try to increase numItermax.\n",
      "  result_code_string = check_result(result_code)\n"
     ]
    }
   ],
   "source": [
    "G0 = ot.emd(a, b, M)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "W = torch.sum(G0 * M)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(1733.2749, device='cuda:0')"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "W"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "geosink",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
