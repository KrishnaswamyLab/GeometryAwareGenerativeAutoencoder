{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "import wandb\n",
    "import sys\n",
    "import matplotlib.pyplot as plt\n",
    "import scprep\n",
    "import pandas as pd\n",
    "sys.path.append('../../src/')\n",
    "from train import load_data\n",
    "# from diffusion import DiffusionModel\n",
    "# from evaluate import get_results\n",
    "from omegaconf import OmegaConf\n",
    "# from main import load_data, make_model\n",
    "import numpy as np\n",
    "import os\n",
    "import glob\n",
    "import matplotlib.animation as animation\n",
    "from matplotlib.animation import PillowWriter\n",
    "import torch\n",
    "from model2 import Autoencoder, Preprocessor, Discriminator\n",
    "import magic\n",
    "import torch\n",
    "import pathlib\n",
    "import copy\n",
    "\n",
    "import wandb\n",
    "import sys\n",
    "import matplotlib.pyplot as plt\n",
    "import scprep\n",
    "import pandas as pd\n",
    "from omegaconf import OmegaConf\n",
    "import os\n",
    "import glob\n",
    "import numpy as np\n",
    "import torch\n",
    "from torch import nn\n",
    "import torch.optim as optim\n",
    "from geodesic import jacobian, velocity, CondCurve, GeodesicBridgeOverfit\n",
    "from plotly3d.plot import scatter, trajectories\n",
    "import torch\n",
    "from torch import nn\n",
    "import pytorch_lightning as pl\n",
    "from procrustes import Procrustes\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm import tqdm\n",
    "import pickle\n",
    "\n",
    "wandb.login()\n",
    "api = wandb.Api()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "def _distance_to_geodesic_criterion(predicted_geodesic, true_geodesic):\n",
    "    # the inputs here are single samples from a geodesic; should be shape num_samples x num_dims\n",
    "    # for each input point, we want the closest distance to any point on the true geodesic using the euclidean distance, torch.cdist\n",
    "    D = torch.cdist(predicted_geodesic, true_geodesic)\n",
    "    min_dists_to_true_geodesic = D.min(dim=1)[0]\n",
    "    # we take the mean of the squared distances\n",
    "    return torch.mean(min_dists_to_true_geodesic**2)\n",
    "# def distance_to_geodesic_criterion(\n",
    "#     predicted_geodesic:torch.Tensor, # size num_geodesics x num_samples x num_dims\n",
    "#     true_geodesic:torch.Tensor, # size num_geodesics num_samples x num_dims. But it's okay if the num_samples are different\n",
    "#     ):\n",
    "#     \"\"\"\n",
    "#     Mean of the squared distances from each predicted point to the closest point on the true geodesic\n",
    "#     \"\"\"\n",
    "#     dists = []\n",
    "#     for i in range(predicted_geodesic.shape[0]):\n",
    "#         dists.append(_distance_to_geodesic_criterion(predicted_geodesic[i], true_geodesic[i]))\n",
    "#     dists = torch.stack(dists)\n",
    "#     return dists.mean()\n",
    "\n",
    "def distance_to_geodesic_criterion_len(\n",
    "    predicted_geodesic:torch.Tensor, # size num_geodesics x num_samples x num_dims\n",
    "    true_geodesic:torch.Tensor, # size num_geodesics num_samples x num_dims. But it's okay if the num_samples are different\n",
    "    lengths=1.,\n",
    "    ):\n",
    "    \"\"\"\n",
    "    Mean of the squared distances from each predicted point to the closest point on the true geodesic\n",
    "    \"\"\"\n",
    "    dists = []\n",
    "    # for i in range(predicted_geodesic.shape[0]):\n",
    "    for i in range(len(predicted_geodesic)):\n",
    "        dists.append(_distance_to_geodesic_criterion(predicted_geodesic[i], true_geodesic[i]))\n",
    "    dists = torch.stack(dists)\n",
    "    dists = dists / lengths\n",
    "    return dists.mean()\n",
    "\n",
    "def distances_to_geodesic(\n",
    "    predicted_geodesic:torch.Tensor, # size num_geodesics x num_samples x num_dims\n",
    "    true_geodesic:torch.Tensor, # size num_geodesics num_samples x num_dims. But it's okay if the num_samples are different\n",
    "    ):\n",
    "    \"\"\"\n",
    "    Mean of the squared distances from each predicted point to the closest point on the true geodesic\n",
    "    \"\"\"\n",
    "    dists = []\n",
    "    # for i in range(predicted_geodesic.shape[0]):\n",
    "    for i in range(len(predicted_geodesic)):\n",
    "        dists.append(_distance_to_geodesic_criterion(predicted_geodesic[i], true_geodesic[i]))\n",
    "    dists = torch.stack(dists)\n",
    "    return dists"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "entity = \"xingzhis\"\n",
    "project = \"dmae\"\n",
    "sweep_id = 'dcxgbhjp'\n",
    "sweep = api.sweep(f\"{entity}/{project}/{sweep_id}\")\n",
    "runs_data = []\n",
    "\n",
    "# Iterate through each run in the sweep\n",
    "for run in sweep.runs:\n",
    "    # Extract metrics and configs\n",
    "    metrics = run.summary._json_dict\n",
    "    configs = run.config\n",
    "    \n",
    "    # Combine metrics and configs, and add run ID\n",
    "    combined_data = {**metrics, **configs, \"run_id\": run.id}\n",
    "    \n",
    "    # Append the combined data to the list\n",
    "    runs_data.append(combined_data)\n",
    "\n",
    "# Create a DataFrame from the runs data\n",
    "df = pd.DataFrame(runs_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "names = df[(df['loss_epoch']!='NaN')][['data_name']].values.flatten()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([], dtype=object)"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[(df['loss_epoch']=='NaN')][['data_name']].values.flatten()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/36 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/gpfs/gibbs/pi/krishnaswamy_smita/xingzhi/.conda_envs/geosink/lib/python3.11/site-packages/pytorch_lightning/utilities/parsing.py:269: UserWarning: Attribute 'preprocessor' is an instance of `nn.Module` and is already saved during checkpointing. It is recommended to ignore them using `self.save_hyperparameters(ignore=['preprocessor'])`.\n",
      "  rank_zero_warn(\n",
      " 39%|███▉      | 14/36 [00:12<00:14,  1.50it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "list index out of range\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 53%|█████▎    | 19/36 [00:17<00:12,  1.31it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "list index out of range\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 36/36 [00:30<00:00,  1.17it/s]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "res_list = []\n",
    "missing = []\n",
    "failed = []\n",
    "\n",
    "for data_name in tqdm(names):\n",
    "    try:\n",
    "        entity = \"xingzhis\"\n",
    "        project = \"dmae\"\n",
    "        sweep_id = 'ys48kno0'\n",
    "        sweep = api.sweep(f\"{entity}/{project}/{sweep_id}\")\n",
    "\n",
    "        runs_data = []\n",
    "\n",
    "        # Iterate through each run in the sweep\n",
    "        for run in sweep.runs:\n",
    "            # Extract metrics and configs\n",
    "            metrics = run.summary._json_dict\n",
    "            configs = run.config\n",
    "            \n",
    "            # Combine metrics and configs, and add run ID\n",
    "            combined_data = {**metrics, **configs, \"run_id\": run.id}\n",
    "            \n",
    "            # Append the combined data to the list\n",
    "            runs_data.append(combined_data)\n",
    "\n",
    "        # Create a DataFrame from the runs data\n",
    "        df = pd.DataFrame(runs_data)\n",
    "\n",
    "        # run_ids = df[(df['data.name'] == data_name) & (df['cfg/loss/weights/cycle'] == 1.) & (df['cfg/dimensions/latent'] == 3)]['run_id']\n",
    "        run_ids = df[(df['data.name'] == data_name) & (df['loss.weights.cycle'] == 1.0) & (df['dimensions.latent'] == 3)]['run_id']\n",
    "        # assert len(run_ids) == 1\n",
    "        if len(run_ids) != 1:\n",
    "            print('AE not found:', run_ids, data_name)\n",
    "        run_id = run_ids.iloc[0]\n",
    "        run = api.run(f\"{entity}/{project}/{run_id}\")\n",
    "        # run = api.run(f\"{entity}/{project}/{run_id}\")\n",
    "        folder_path = '../../src/wandb/'\n",
    "        cfg = OmegaConf.create(run.config)\n",
    "        folder_list = glob.glob(f\"{folder_path}*{run.id}*\")\n",
    "        ckpt_files = glob.glob(f\"{folder_list[0]}/files/*.ckpt\")\n",
    "        ckpt_path = ckpt_files[0]\n",
    "        cfg.data.root = '../' + cfg.data.root\n",
    "        model = Autoencoder.load_from_checkpoint(ckpt_path)\n",
    "        data = np.load(f\"{cfg.data.root}/{cfg.data.name}{cfg.data.filetype}\", allow_pickle=True)\n",
    "\n",
    "\n",
    "\n",
    "        # sweep_id = 'ywep3ixr'\n",
    "        # sweep = api.sweep(f\"{entity}/{project}/{sweep_id}\")\n",
    "        # # Initialize an empty list to store run data\n",
    "        # runs_data = []\n",
    "\n",
    "        # # Iterate through each run in the sweep\n",
    "        # for run in sweep.runs:\n",
    "        #     # Extract metrics and configs\n",
    "        #     metrics = run.summary._json_dict\n",
    "        #     configs = run.config\n",
    "            \n",
    "        #     # Combine metrics and configs, and add run ID\n",
    "        #     combined_data = {**metrics, **configs, \"run_id\": run.id}\n",
    "            \n",
    "        #     # Append the combined data to the list\n",
    "        #     runs_data.append(combined_data)\n",
    "\n",
    "        # # Create a DataFrame from the runs data\n",
    "        # df = pd.DataFrame(runs_data)\n",
    "        # run_ids = df[(df['data.name'] == data_name)][['run_id']]\n",
    "        # assert len(run_ids) == 1\n",
    "        # run_id = run_ids.iloc[0]\n",
    "        # run = api.run(f\"{entity}/{project}/{run_ids.iloc[0].values[0]}\")\n",
    "        # folder_path = '../../src/wandb/'\n",
    "        # cfg = OmegaConf.create(run.config)\n",
    "        # folder_list = glob.glob(f\"{folder_path}*{run.id}*\")\n",
    "        # ckpt_files = glob.glob(f\"{folder_list[0]}/files/*.ckpt\")\n",
    "        # ckpt_path = ckpt_files[0]\n",
    "        # cfg.data.root = '../' + cfg.data.root\n",
    "        # discriminator = Discriminator.load_from_checkpoint(ckpt_path)\n",
    "\n",
    "\n",
    "\n",
    "        entity = \"xingzhis\"\n",
    "        project = \"dmae\"\n",
    "        sweep_id = 'dcxgbhjp'\n",
    "        sweep = api.sweep(f\"{entity}/{project}/{sweep_id}\")\n",
    "        runs_data = []\n",
    "\n",
    "        # Iterate through each run in the sweep\n",
    "        for run in sweep.runs:\n",
    "            # Extract metrics and configs\n",
    "            metrics = run.summary._json_dict\n",
    "            configs = run.config\n",
    "            \n",
    "            # Combine metrics and configs, and add run ID\n",
    "            combined_data = {**metrics, **configs, \"run_id\": run.id}\n",
    "            \n",
    "            # Append the combined data to the list\n",
    "            runs_data.append(combined_data)\n",
    "\n",
    "        # Create a DataFrame from the runs data\n",
    "        df = pd.DataFrame(runs_data)\n",
    "\n",
    "        run_ids = df[(df['data_name'] == data_name) & (df['loss_epoch'] != 'NaN') & (df['dimensions_latent'] == 3)]['run_id']\n",
    "        # assert len(run_ids) == 1\n",
    "        if len(run_ids) != 1:\n",
    "            print('Geod not found', run_ids, data_name)\n",
    "        run_id = run_ids.iloc[0]\n",
    "        run = api.run(f\"{entity}/{project}/{run_id}\")\n",
    "        cfg_main = OmegaConf.create(run.config)\n",
    "        folder_path = '../geodesic_on_datasets//wandb/'\n",
    "        folder_list = glob.glob(f\"{folder_path}*{run.id}*\")\n",
    "        ckpt_files = glob.glob(f\"{folder_list[0]}/files/*.ckpt\")\n",
    "        ckpt_path = ckpt_files[0]\n",
    "\n",
    "        x = torch.tensor(data['data'], dtype=torch.float32, device=model.device)\n",
    "        xbatch = torch.tensor(data['start_points'], dtype=x.dtype, device=x.device)\n",
    "        xendbatch = torch.tensor(data['end_points'], dtype=x.dtype, device=x.device)\n",
    "        # xbatch = model.encoder.preprocessor.normalize(xbatch)\n",
    "        # xendbatch = model.encoder.preprocessor.normalize(xendbatch)\n",
    "        # if cfg_main.overfit:\n",
    "        #     ids = torch.eye(xbatch.size(0))\n",
    "        # else:\n",
    "        ids = torch.zeros((xbatch.size(0),1))\n",
    "        dataset = TensorDataset(xbatch, xendbatch, ids)\n",
    "        dataloader = DataLoader(dataset, batch_size=len(x), shuffle=False)\n",
    "\n",
    "        for param in model.encoder.parameters():\n",
    "            param.requires_grad = False\n",
    "        # def func(x):\n",
    "        #     return model.encoder(x)\n",
    "        # for param in discriminator.parameters():\n",
    "        #     param.requires_grad = False\n",
    "        # def discriminator_func_for_grad(x):\n",
    "        #     return discriminator.positive_proba(x, normalize=False).reshape(-1,1)\n",
    "        # def discriminator_func(x):\n",
    "        #     return discriminator.positive_proba(x, normalize=False).reshape(-1,1)\n",
    "        ofm = lambda x: x\n",
    "        gbmodel = GeodesicBridgeOverfit.load_from_checkpoint(\n",
    "            checkpoint_path=ckpt_path,\n",
    "            func=ofm,\n",
    "            # func = enc_func,\n",
    "            # discriminator_func=disc_func_pen,\n",
    "            # discriminator_func_for_grad=discriminator_func_for_grad,\n",
    "            input_dim=x.size(1), \n",
    "            hidden_dim=64, \n",
    "            scale_factor=1, \n",
    "            symmetric=True, \n",
    "            num_layers=3, \n",
    "            n_tsteps=100, \n",
    "            lr=1e-3, \n",
    "            weight_decay=1e-3,\n",
    "            discriminator_weight=0.,\n",
    "            discriminator_func_for_grad_weight=0.,\n",
    "            id_dim=1,\n",
    "            id_emb_dim=1,\n",
    "            density_weight=0.,\n",
    "            length_weight=1.,\n",
    "        )\n",
    "\n",
    "        # batch = next(iter(dataloader))\n",
    "        # x0, x1, ids = batch\n",
    "        try:\n",
    "            data_gt = np.load(f\"/gpfs/gibbs/pi/krishnaswamy_smita/xingzhi/dmae/data/neurips_results/toy/gt/{data_name}.npz\", allow_pickle=True)\n",
    "        except:\n",
    "            print(f\"CANNOT FIND FILE {data_name}.npz\")\n",
    "            missing.append(data_name)\n",
    "            continue\n",
    "        xbatch = torch.tensor(data_gt['start_points'], dtype=x.dtype, device=x.device)\n",
    "        xendbatch = torch.tensor(data_gt['end_points'], dtype=x.dtype, device=x.device)\n",
    "        x0 = xbatch\n",
    "        x1 = xendbatch\n",
    "        # xbatch = model.encoder.preprocessor.normalize(xbatch)\n",
    "        # xendbatch = model.encoder.preprocessor.normalize(xendbatch)\n",
    "        ids = torch.zeros((xbatch.size(0),1))\n",
    "        # ids = torch.eye((xbatch.size(0)))\n",
    "\n",
    "        # dataset = TensorDataset(xbatch, xendbatch, ids)\n",
    "        # dataloader = DataLoader(dataset, batch_size=len(z), shuffle=True)\n",
    "\n",
    "        def cc_func(x0, x1, t):\n",
    "            return gbmodel.cc(x0, x1, t, ids)\n",
    "        vectors = velocity(cc_func, gbmodel.ts, x0, x1)\n",
    "        cc_pts = gbmodel.cc(x0, x1, gbmodel.ts, ids)\n",
    "        vectors_flat = vectors.flatten(0,1)\n",
    "        cc_pts_flat = cc_pts.flatten(0, 1)\n",
    "        jac_flat = jacobian(gbmodel.func, cc_pts_flat)\n",
    "        length_all = torch.sqrt((torch.einsum(\"nij,nj->ni\", jac_flat, vectors_flat)**2).sum(axis=1))\n",
    "        length_all = length_all.reshape(vectors.shape[0], vectors.shape[1])\n",
    "        length = length_all.mean(axis=0)\n",
    "\n",
    "        geods = (cc_pts_flat).reshape(cc_pts.shape)\n",
    "        length2 = torch.sqrt(torch.diff(geods, axis=0)**2).sum(axis=-1).sum(axis=0)\n",
    "\n",
    "\n",
    "        # plt.scatter(length2.detach().numpy(), data_gt['geodesic_lengths'])\n",
    "        # plt.title(data_name)\n",
    "        # plt.show()\n",
    "\n",
    "        # gt_len = torch.tensor(data_gt['geodesic_lengths'])\n",
    "        true_geod = torch.tensor(data_gt['geodesics'], dtype=torch.float32)\n",
    "        gt_len = torch.sqrt(torch.diff(true_geod.permute(1,0,2), axis=0)**2).sum(axis=-1).sum(axis=0)\n",
    "        corr = np.corrcoef(length.detach().numpy(), gt_len.cpu().numpy())[0,1]\n",
    "        mse = ((length.detach().numpy() - gt_len.cpu().numpy())**2).mean()\n",
    "        dist2geod = distance_to_geodesic_criterion_len(geods.permute(1,0,2), true_geod, lengths=gt_len).detach().numpy()\n",
    "\n",
    "        res_list.append(dict(\n",
    "            name=data_name,\n",
    "            length_corr=corr,\n",
    "            length_mse=mse,\n",
    "            dist2geod=dist2geod\n",
    "        ))\n",
    "    except Exception as e:\n",
    "        failed.append(data_name)\n",
    "        print(e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['saddle_10_0.1', 'saddle_50_0.1']"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "failed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "res_df = pd.DataFrame(res_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>name</th>\n",
       "      <th>length_corr</th>\n",
       "      <th>length_mse</th>\n",
       "      <th>dist2geod</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>torus_5_0.1</td>\n",
       "      <td>0.909735</td>\n",
       "      <td>9.049824</td>\n",
       "      <td>0.050267942</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>torus_none_0.1</td>\n",
       "      <td>0.633220</td>\n",
       "      <td>4.541703</td>\n",
       "      <td>0.23434603</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>torus_15_0.7</td>\n",
       "      <td>0.592362</td>\n",
       "      <td>14.874922</td>\n",
       "      <td>1.0364368</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>torus_15_0.1</td>\n",
       "      <td>0.979370</td>\n",
       "      <td>28.355350</td>\n",
       "      <td>0.05461672</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>torus_50_0.1</td>\n",
       "      <td>0.930231</td>\n",
       "      <td>33.590221</td>\n",
       "      <td>0.11301482</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>torus_15_0.3</td>\n",
       "      <td>0.917425</td>\n",
       "      <td>22.094746</td>\n",
       "      <td>0.22908823</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>torus_15_0.5</td>\n",
       "      <td>0.808113</td>\n",
       "      <td>18.354548</td>\n",
       "      <td>0.4918476</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>torus_10_0.1</td>\n",
       "      <td>0.905920</td>\n",
       "      <td>14.563463</td>\n",
       "      <td>0.08488769</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>saddle_15_0.1</td>\n",
       "      <td>0.903782</td>\n",
       "      <td>3.957337</td>\n",
       "      <td>0.047347892</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>saddle_15_0.7</td>\n",
       "      <td>0.199747</td>\n",
       "      <td>5.126626</td>\n",
       "      <td>1.991108</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>saddle_15_0</td>\n",
       "      <td>0.971322</td>\n",
       "      <td>5.043397</td>\n",
       "      <td>0.011780437</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>torus_15_0</td>\n",
       "      <td>0.979411</td>\n",
       "      <td>25.834690</td>\n",
       "      <td>0.021374902</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>saddle_15_0.5</td>\n",
       "      <td>0.462851</td>\n",
       "      <td>1.031825</td>\n",
       "      <td>0.9085722</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>hemisphere_5_0.1</td>\n",
       "      <td>0.879877</td>\n",
       "      <td>0.479798</td>\n",
       "      <td>0.041763626</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>hemisphere_50_0.1</td>\n",
       "      <td>0.814824</td>\n",
       "      <td>4.481339</td>\n",
       "      <td>0.2302659</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>saddle_none_0.1</td>\n",
       "      <td>0.910447</td>\n",
       "      <td>0.744173</td>\n",
       "      <td>0.02441574</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>saddle_15_0.3</td>\n",
       "      <td>0.677460</td>\n",
       "      <td>1.565257</td>\n",
       "      <td>0.3783231</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>saddle_5_0.1</td>\n",
       "      <td>0.869803</td>\n",
       "      <td>1.333473</td>\n",
       "      <td>0.023783892</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>hemisphere_10_0.1</td>\n",
       "      <td>0.837628</td>\n",
       "      <td>2.338800</td>\n",
       "      <td>0.06434282</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>hemisphere_15_0.3</td>\n",
       "      <td>0.255365</td>\n",
       "      <td>2.217846</td>\n",
       "      <td>0.66211265</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>hemisphere_15_0.7</td>\n",
       "      <td>0.000719</td>\n",
       "      <td>3.962232</td>\n",
       "      <td>2.033214</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>hemisphere_15_0</td>\n",
       "      <td>0.979427</td>\n",
       "      <td>3.578341</td>\n",
       "      <td>0.011829333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>ellipsoid_15_0.5</td>\n",
       "      <td>0.552981</td>\n",
       "      <td>10.483925</td>\n",
       "      <td>0.6171087</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>hemisphere_15_0.5</td>\n",
       "      <td>0.015143</td>\n",
       "      <td>2.183568</td>\n",
       "      <td>1.0684398</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>ellipsoid_10_0.1</td>\n",
       "      <td>0.665957</td>\n",
       "      <td>8.410280</td>\n",
       "      <td>0.06023972</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>ellipsoid_5_0.1</td>\n",
       "      <td>0.592550</td>\n",
       "      <td>10.165902</td>\n",
       "      <td>0.04837641</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>ellipsoid_15_0.7</td>\n",
       "      <td>0.309140</td>\n",
       "      <td>10.468890</td>\n",
       "      <td>1.0292432</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>ellipsoid_none_0.1</td>\n",
       "      <td>0.451384</td>\n",
       "      <td>5.081788</td>\n",
       "      <td>0.13506278</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>hemisphere_15_0.1</td>\n",
       "      <td>0.806112</td>\n",
       "      <td>3.945384</td>\n",
       "      <td>0.07205766</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>hemisphere_none_0.1</td>\n",
       "      <td>0.820485</td>\n",
       "      <td>0.523929</td>\n",
       "      <td>0.05028806</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>ellipsoid_50_0.1</td>\n",
       "      <td>0.644948</td>\n",
       "      <td>23.896164</td>\n",
       "      <td>0.1570367</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>ellipsoid_15_0.1</td>\n",
       "      <td>0.841202</td>\n",
       "      <td>19.039576</td>\n",
       "      <td>0.058348894</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>ellipsoid_15_0</td>\n",
       "      <td>0.924593</td>\n",
       "      <td>13.305796</td>\n",
       "      <td>0.027895689</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>ellipsoid_15_0.3</td>\n",
       "      <td>0.582577</td>\n",
       "      <td>13.623917</td>\n",
       "      <td>0.30634502</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                   name  length_corr  length_mse    dist2geod\n",
       "0           torus_5_0.1     0.909735    9.049824  0.050267942\n",
       "1        torus_none_0.1     0.633220    4.541703   0.23434603\n",
       "2          torus_15_0.7     0.592362   14.874922    1.0364368\n",
       "3          torus_15_0.1     0.979370   28.355350   0.05461672\n",
       "4          torus_50_0.1     0.930231   33.590221   0.11301482\n",
       "5          torus_15_0.3     0.917425   22.094746   0.22908823\n",
       "6          torus_15_0.5     0.808113   18.354548    0.4918476\n",
       "7          torus_10_0.1     0.905920   14.563463   0.08488769\n",
       "8         saddle_15_0.1     0.903782    3.957337  0.047347892\n",
       "9         saddle_15_0.7     0.199747    5.126626     1.991108\n",
       "10          saddle_15_0     0.971322    5.043397  0.011780437\n",
       "11           torus_15_0     0.979411   25.834690  0.021374902\n",
       "12        saddle_15_0.5     0.462851    1.031825    0.9085722\n",
       "13     hemisphere_5_0.1     0.879877    0.479798  0.041763626\n",
       "14    hemisphere_50_0.1     0.814824    4.481339    0.2302659\n",
       "15      saddle_none_0.1     0.910447    0.744173   0.02441574\n",
       "16        saddle_15_0.3     0.677460    1.565257    0.3783231\n",
       "17         saddle_5_0.1     0.869803    1.333473  0.023783892\n",
       "18    hemisphere_10_0.1     0.837628    2.338800   0.06434282\n",
       "19    hemisphere_15_0.3     0.255365    2.217846   0.66211265\n",
       "20    hemisphere_15_0.7     0.000719    3.962232     2.033214\n",
       "21      hemisphere_15_0     0.979427    3.578341  0.011829333\n",
       "22     ellipsoid_15_0.5     0.552981   10.483925    0.6171087\n",
       "23    hemisphere_15_0.5     0.015143    2.183568    1.0684398\n",
       "24     ellipsoid_10_0.1     0.665957    8.410280   0.06023972\n",
       "25      ellipsoid_5_0.1     0.592550   10.165902   0.04837641\n",
       "26     ellipsoid_15_0.7     0.309140   10.468890    1.0292432\n",
       "27   ellipsoid_none_0.1     0.451384    5.081788   0.13506278\n",
       "28    hemisphere_15_0.1     0.806112    3.945384   0.07205766\n",
       "29  hemisphere_none_0.1     0.820485    0.523929   0.05028806\n",
       "30     ellipsoid_50_0.1     0.644948   23.896164    0.1570367\n",
       "31     ellipsoid_15_0.1     0.841202   19.039576  0.058348894\n",
       "32       ellipsoid_15_0     0.924593   13.305796  0.027895689\n",
       "33     ellipsoid_15_0.3     0.582577   13.623917   0.30634502"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "res_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "dijkstra_path = '../dijkstra/noisy_results/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/36 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 36/36 [00:00<00:00, 94.44it/s] \n"
     ]
    }
   ],
   "source": [
    "missing = []\n",
    "res_list = []\n",
    "for data_name in tqdm(names):\n",
    "# try:\n",
    "    with open(f\"{dijkstra_path}/{data_name}.pkl\", 'rb') as f:\n",
    "        dijkstra = pickle.load(f)\n",
    "    geods, length = dijkstra\n",
    "    geods = [g.float() for g in geods]\n",
    "    length = length.float()\n",
    "    try:\n",
    "        data_gt = np.load(f\"/gpfs/gibbs/pi/krishnaswamy_smita/xingzhi/dmae/data/neurips_results/toy/gt/{data_name}.npz\", allow_pickle=True)\n",
    "    except:\n",
    "        print(f\"CANNOT FIND FILE {data_name}.npz\")\n",
    "        missing.append(data_name)\n",
    "        continue\n",
    "    true_geod = torch.tensor(data_gt['geodesics'], dtype=torch.float32)\n",
    "    gt_len = torch.sqrt(torch.diff(true_geod.permute(1,0,2), axis=0)**2).sum(axis=-1).sum(axis=0)\n",
    "    corr = np.corrcoef(length.detach().numpy(), gt_len.cpu().numpy())[0,1]\n",
    "    mse = ((length.detach().numpy() - gt_len.cpu().numpy())**2).mean()\n",
    "    dist2geod = distance_to_geodesic_criterion_len(geods, true_geod, lengths=gt_len).detach().numpy()\n",
    "    res_list.append(dict(\n",
    "        name=data_name,\n",
    "        length_corr=corr,\n",
    "        length_mse=mse,\n",
    "        dist2geod=dist2geod\n",
    "    ))\n",
    "# except Exception as e:\n",
    "#     print(e)\n",
    "#     failed.append(data_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "res_df2 = pd.DataFrame(res_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>name</th>\n",
       "      <th>length_corr</th>\n",
       "      <th>length_mse</th>\n",
       "      <th>dist2geod</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>torus_5_0.1</td>\n",
       "      <td>0.100787</td>\n",
       "      <td>8.537322</td>\n",
       "      <td>0.90323555</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>torus_none_0.1</td>\n",
       "      <td>-0.367631</td>\n",
       "      <td>11.190136</td>\n",
       "      <td>2.4193416</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>torus_15_0.7</td>\n",
       "      <td>-0.382353</td>\n",
       "      <td>30.718500</td>\n",
       "      <td>2.4563715</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>torus_15_0.1</td>\n",
       "      <td>0.096332</td>\n",
       "      <td>24.826366</td>\n",
       "      <td>1.5774175</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>torus_50_0.1</td>\n",
       "      <td>0.045874</td>\n",
       "      <td>25.839344</td>\n",
       "      <td>1.4714675</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>torus_15_0.3</td>\n",
       "      <td>-0.105070</td>\n",
       "      <td>24.662868</td>\n",
       "      <td>1.8594033</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>torus_15_0.5</td>\n",
       "      <td>-0.049811</td>\n",
       "      <td>21.943882</td>\n",
       "      <td>1.7094434</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>torus_10_0.1</td>\n",
       "      <td>-0.194519</td>\n",
       "      <td>16.374231</td>\n",
       "      <td>2.2948985</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>saddle_15_0.1</td>\n",
       "      <td>0.108708</td>\n",
       "      <td>2.732261</td>\n",
       "      <td>0.24037907</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>saddle_15_0.7</td>\n",
       "      <td>0.159378</td>\n",
       "      <td>13.317421</td>\n",
       "      <td>2.003242</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>saddle_15_0</td>\n",
       "      <td>-0.008410</td>\n",
       "      <td>7.355129</td>\n",
       "      <td>0.24017484</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>torus_15_0</td>\n",
       "      <td>0.319627</td>\n",
       "      <td>29.023834</td>\n",
       "      <td>1.0033163</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>saddle_15_0.5</td>\n",
       "      <td>-0.081285</td>\n",
       "      <td>5.309648</td>\n",
       "      <td>1.1015551</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>saddle_10_0.1</td>\n",
       "      <td>0.224763</td>\n",
       "      <td>2.346261</td>\n",
       "      <td>0.75169796</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>hemisphere_5_0.1</td>\n",
       "      <td>-0.181719</td>\n",
       "      <td>1.207179</td>\n",
       "      <td>0.797387</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>hemisphere_50_0.1</td>\n",
       "      <td>0.082505</td>\n",
       "      <td>6.768186</td>\n",
       "      <td>0.636538</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>saddle_none_0.1</td>\n",
       "      <td>-0.181110</td>\n",
       "      <td>1.621648</td>\n",
       "      <td>0.47909737</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>saddle_15_0.3</td>\n",
       "      <td>0.205681</td>\n",
       "      <td>1.843694</td>\n",
       "      <td>0.587716</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>saddle_50_0.1</td>\n",
       "      <td>-0.303703</td>\n",
       "      <td>5.746846</td>\n",
       "      <td>0.49245992</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>saddle_5_0.1</td>\n",
       "      <td>-0.096190</td>\n",
       "      <td>2.056057</td>\n",
       "      <td>0.46577772</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>hemisphere_10_0.1</td>\n",
       "      <td>0.298607</td>\n",
       "      <td>2.159470</td>\n",
       "      <td>0.5543449</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>hemisphere_15_0.3</td>\n",
       "      <td>-0.171302</td>\n",
       "      <td>5.309527</td>\n",
       "      <td>1.4687157</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>hemisphere_15_0.7</td>\n",
       "      <td>-0.044558</td>\n",
       "      <td>12.823871</td>\n",
       "      <td>2.198113</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>hemisphere_15_0</td>\n",
       "      <td>0.089341</td>\n",
       "      <td>4.923058</td>\n",
       "      <td>0.9637364</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>ellipsoid_15_0.5</td>\n",
       "      <td>-0.071407</td>\n",
       "      <td>13.584180</td>\n",
       "      <td>1.7208769</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>hemisphere_15_0.5</td>\n",
       "      <td>-0.183489</td>\n",
       "      <td>7.349617</td>\n",
       "      <td>1.6729208</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>ellipsoid_10_0.1</td>\n",
       "      <td>0.269387</td>\n",
       "      <td>7.046156</td>\n",
       "      <td>1.0717319</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>ellipsoid_5_0.1</td>\n",
       "      <td>0.274413</td>\n",
       "      <td>8.941875</td>\n",
       "      <td>1.0785444</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>ellipsoid_15_0.7</td>\n",
       "      <td>0.363560</td>\n",
       "      <td>11.054895</td>\n",
       "      <td>2.0548315</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>ellipsoid_none_0.1</td>\n",
       "      <td>-0.225920</td>\n",
       "      <td>6.647122</td>\n",
       "      <td>1.0649941</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>hemisphere_15_0.1</td>\n",
       "      <td>0.599986</td>\n",
       "      <td>1.464915</td>\n",
       "      <td>0.43287188</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>hemisphere_none_0.1</td>\n",
       "      <td>0.022110</td>\n",
       "      <td>1.203106</td>\n",
       "      <td>0.93164885</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>ellipsoid_50_0.1</td>\n",
       "      <td>0.074746</td>\n",
       "      <td>13.553679</td>\n",
       "      <td>0.5734172</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>ellipsoid_15_0.1</td>\n",
       "      <td>0.332634</td>\n",
       "      <td>14.682520</td>\n",
       "      <td>1.0224384</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>ellipsoid_15_0</td>\n",
       "      <td>0.309180</td>\n",
       "      <td>17.298109</td>\n",
       "      <td>0.7885768</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>ellipsoid_15_0.3</td>\n",
       "      <td>0.229642</td>\n",
       "      <td>10.378992</td>\n",
       "      <td>0.91572255</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                   name  length_corr  length_mse   dist2geod\n",
       "0           torus_5_0.1     0.100787    8.537322  0.90323555\n",
       "1        torus_none_0.1    -0.367631   11.190136   2.4193416\n",
       "2          torus_15_0.7    -0.382353   30.718500   2.4563715\n",
       "3          torus_15_0.1     0.096332   24.826366   1.5774175\n",
       "4          torus_50_0.1     0.045874   25.839344   1.4714675\n",
       "5          torus_15_0.3    -0.105070   24.662868   1.8594033\n",
       "6          torus_15_0.5    -0.049811   21.943882   1.7094434\n",
       "7          torus_10_0.1    -0.194519   16.374231   2.2948985\n",
       "8         saddle_15_0.1     0.108708    2.732261  0.24037907\n",
       "9         saddle_15_0.7     0.159378   13.317421    2.003242\n",
       "10          saddle_15_0    -0.008410    7.355129  0.24017484\n",
       "11           torus_15_0     0.319627   29.023834   1.0033163\n",
       "12        saddle_15_0.5    -0.081285    5.309648   1.1015551\n",
       "13        saddle_10_0.1     0.224763    2.346261  0.75169796\n",
       "14     hemisphere_5_0.1    -0.181719    1.207179    0.797387\n",
       "15    hemisphere_50_0.1     0.082505    6.768186    0.636538\n",
       "16      saddle_none_0.1    -0.181110    1.621648  0.47909737\n",
       "17        saddle_15_0.3     0.205681    1.843694    0.587716\n",
       "18        saddle_50_0.1    -0.303703    5.746846  0.49245992\n",
       "19         saddle_5_0.1    -0.096190    2.056057  0.46577772\n",
       "20    hemisphere_10_0.1     0.298607    2.159470   0.5543449\n",
       "21    hemisphere_15_0.3    -0.171302    5.309527   1.4687157\n",
       "22    hemisphere_15_0.7    -0.044558   12.823871    2.198113\n",
       "23      hemisphere_15_0     0.089341    4.923058   0.9637364\n",
       "24     ellipsoid_15_0.5    -0.071407   13.584180   1.7208769\n",
       "25    hemisphere_15_0.5    -0.183489    7.349617   1.6729208\n",
       "26     ellipsoid_10_0.1     0.269387    7.046156   1.0717319\n",
       "27      ellipsoid_5_0.1     0.274413    8.941875   1.0785444\n",
       "28     ellipsoid_15_0.7     0.363560   11.054895   2.0548315\n",
       "29   ellipsoid_none_0.1    -0.225920    6.647122   1.0649941\n",
       "30    hemisphere_15_0.1     0.599986    1.464915  0.43287188\n",
       "31  hemisphere_none_0.1     0.022110    1.203106  0.93164885\n",
       "32     ellipsoid_50_0.1     0.074746   13.553679   0.5734172\n",
       "33     ellipsoid_15_0.1     0.332634   14.682520   1.0224384\n",
       "34       ellipsoid_15_0     0.309180   17.298109   0.7885768\n",
       "35     ellipsoid_15_0.3     0.229642   10.378992  0.91572255"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "res_df2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "res_df2.to_csv('dijkstra_results.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
