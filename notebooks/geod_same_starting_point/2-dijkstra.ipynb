{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO: Using pytorch backend\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "from autometric.geodesics import DjikstraGeodesic\n",
    "from autometric.datasets import Hemisphere, Ellipsoid, Saddle, Torus\n",
    "import pathlib\n",
    "import pickle\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_path = \"../../data/neurips_results/toy/visualize2/\"\n",
    "data_names = ['hemisphere', 'ellipsoid', 'saddle', 'torus']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_points_per_geodesic = 3000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "out_path = '../../data/neurips_results/toy/visualize_gt/'\n",
    "pathlib.Path(out_path).mkdir(parents=True, exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "data_name = 'hemisphere'\n",
    "data = np.load(f'{data_path}/{data_name}.npz')\n",
    "points = data['X']\n",
    "hs = Hemisphere(num_points=3000)\n",
    "hs.X = torch.tensor(points, dtype=torch.float32)\n",
    "start_points = torch.tensor(data['start_points'], dtype=torch.float32)\n",
    "end_points = torch.tensor(data['end_points'], dtype=torch.float32)\n",
    "ts = np.linspace(0, 1, num_points_per_geodesic)\n",
    "gs, ls = hs.geodesics(start_points, end_points, ts)\n",
    "if isinstance(gs[0], torch.Tensor):\n",
    "    gs = [g.detach().numpy() for g in gs]\n",
    "    ls = ls.numpy()\n",
    "max_len = max([len(g) for g in gs])\n",
    "# pad the ends of the list with copies of the last element to make them all the same length, using np.vstack\n",
    "gs = [np.vstack([g[:-1], np.repeat(g[-1][None,:], max_len - len(g) + 1, axis = 0)]) for g in gs]\n",
    "data_dict = {n:data[n] for n in data.files}\n",
    "data_dict['geodesics'] = gs\n",
    "data_dict['geodesic_lengths'] = ls\n",
    "np.savez(f'{out_path}/{data_name}.npz', **data_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[6], line 9\u001b[0m\n\u001b[1;32m      7\u001b[0m end_points \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39mtensor(data[\u001b[39m'\u001b[39m\u001b[39mend_points\u001b[39m\u001b[39m'\u001b[39m], dtype\u001b[39m=\u001b[39mtorch\u001b[39m.\u001b[39mfloat32)\n\u001b[1;32m      8\u001b[0m ts \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39mlinspace(\u001b[39m0\u001b[39m, \u001b[39m1\u001b[39m, num_points_per_geodesic)\n\u001b[0;32m----> 9\u001b[0m gs, ls \u001b[39m=\u001b[39m hs\u001b[39m.\u001b[39;49mgeodesics(start_points, end_points, ts)\n\u001b[1;32m     10\u001b[0m data_dict \u001b[39m=\u001b[39m {n:data[n] \u001b[39mfor\u001b[39;00m n \u001b[39min\u001b[39;00m data\u001b[39m.\u001b[39mfiles}\n\u001b[1;32m     11\u001b[0m data_dict[\u001b[39m'\u001b[39m\u001b[39mgeodesics\u001b[39m\u001b[39m'\u001b[39m] \u001b[39m=\u001b[39m gs\n",
      "File \u001b[0;32m/gpfs/gibbs/pi/krishnaswamy_smita/xingzhi/dmae/src/autometric/src/autometric/datasets.py:307\u001b[0m, in \u001b[0;36mToyManifold.geodesics\u001b[0;34m(self, start_points, end_points, ts)\u001b[0m\n\u001b[1;32m    305\u001b[0m     g, l \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mpairwise_geodesic(start_points[i], end_points[i], ts)\n\u001b[1;32m    306\u001b[0m \u001b[39melse\u001b[39;00m: \u001b[39m# use the djikstra algorithm\u001b[39;00m\n\u001b[0;32m--> 307\u001b[0m     g, l \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mpairwise_geodesic_via_djikstra(start_points[i], end_points[i], ts)\n\u001b[1;32m    308\u001b[0m \u001b[39m# convert g to double\u001b[39;00m\n\u001b[1;32m    309\u001b[0m g \u001b[39m=\u001b[39m g\u001b[39m.\u001b[39mdouble()\n",
      "File \u001b[0;32m/gpfs/gibbs/pi/krishnaswamy_smita/xingzhi/dmae/src/autometric/src/autometric/datasets.py:261\u001b[0m, in \u001b[0;36mToyManifold.pairwise_geodesic_via_djikstra\u001b[0;34m(self, a, b, ts, k)\u001b[0m\n\u001b[1;32m    259\u001b[0m \u001b[39mfor\u001b[39;00m i \u001b[39min\u001b[39;00m \u001b[39mrange\u001b[39m(\u001b[39mlen\u001b[39m(X_combined)):\n\u001b[1;32m    260\u001b[0m     \u001b[39mfor\u001b[39;00m j \u001b[39min\u001b[39;00m \u001b[39mrange\u001b[39m(\u001b[39m1\u001b[39m, k\u001b[39m+\u001b[39m\u001b[39m1\u001b[39m):  \u001b[39m# start from 1 to avoid self-loop (i.e., point itself)\u001b[39;00m\n\u001b[0;32m--> 261\u001b[0m         G\u001b[39m.\u001b[39madd_edge(i, indices[i][j], weight \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39;49mlinalg\u001b[39m.\u001b[39;49mnorm(X_combined[i] \u001b[39m-\u001b[39;49m X_combined[indices[i][j]]))\n\u001b[1;32m    262\u001b[0m         G\u001b[39m.\u001b[39madd_edge(indices[i][j], i, weight \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39mlinalg\u001b[39m.\u001b[39mnorm(X_combined[i] \u001b[39m-\u001b[39m X_combined[indices[i][j]]))\n\u001b[1;32m    265\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mG \u001b[39m=\u001b[39m G\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "data_name = 'ellipsoid'\n",
    "data = np.load(f'{data_path}/{data_name}.npz')\n",
    "points = data['X']\n",
    "hs = Ellipsoid(num_points=3000)\n",
    "hs.X = torch.tensor(points, dtype=torch.float32)\n",
    "start_points = torch.tensor(data['start_points'], dtype=torch.float32)\n",
    "end_points = torch.tensor(data['end_points'], dtype=torch.float32)\n",
    "ts = np.linspace(0, 1, num_points_per_geodesic)\n",
    "gs, ls = hs.geodesics(start_points, end_points, ts)\n",
    "if isinstance(gs[0], torch.Tensor):\n",
    "    gs = [g.detach().numpy() for g in gs]\n",
    "    ls = ls.numpy()\n",
    "max_len = max([len(g) for g in gs])\n",
    "# pad the ends of the list with copies of the last element to make them all the same length, using np.vstack\n",
    "gs = [np.vstack([g[:-1], np.repeat(g[-1][None,:], max_len - len(g) + 1, axis = 0)]) for g in gs]\n",
    "data_dict = {n:data[n] for n in data.files}\n",
    "data_dict['geodesics'] = gs\n",
    "data_dict['geodesic_lengths'] = ls\n",
    "np.savez(f'{out_path}/{data_name}.npz', **data_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_name = 'saddle'\n",
    "data = np.load(f'{data_path}/{data_name}.npz')\n",
    "points = data['X']\n",
    "hs = Saddle(num_points=3000)\n",
    "hs.X = torch.tensor(points, dtype=torch.float32)\n",
    "start_points = torch.tensor(data['start_points'], dtype=torch.float32)\n",
    "end_points = torch.tensor(data['end_points'], dtype=torch.float32)\n",
    "ts = np.linspace(0, 1, num_points_per_geodesic)\n",
    "gs, ls = hs.geodesics(start_points, end_points, ts)\n",
    "if isinstance(gs[0], torch.Tensor):\n",
    "    gs = [g.detach().numpy() for g in gs]\n",
    "    ls = ls.numpy()\n",
    "max_len = max([len(g) for g in gs])\n",
    "# pad the ends of the list with copies of the last element to make them all the same length, using np.vstack\n",
    "gs = [np.vstack([g[:-1], np.repeat(g[-1][None,:], max_len - len(g) + 1, axis = 0)]) for g in gs]\n",
    "data_dict = {n:data[n] for n in data.files}\n",
    "data_dict['geodesics'] = gs\n",
    "data_dict['geodesic_lengths'] = ls\n",
    "np.savez(f'{out_path}/{data_name}.npz', **data_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_name = 'torus'\n",
    "data = np.load(f'{data_path}/{data_name}.npz')\n",
    "points = data['X']\n",
    "hs = Torus(num_points=3000)\n",
    "hs.X = torch.tensor(points, dtype=torch.float32)\n",
    "start_points = torch.tensor(data['start_points'], dtype=torch.float32)\n",
    "end_points = torch.tensor(data['end_points'], dtype=torch.float32)\n",
    "ts = np.linspace(0, 1, num_points_per_geodesic)\n",
    "gs, ls = hs.geodesics(start_points, end_points, ts)\n",
    "if isinstance(gs[0], torch.Tensor):\n",
    "    gs = [g.detach().numpy() for g in gs]\n",
    "    ls = ls.numpy()\n",
    "max_len = max([len(g) for g in gs])\n",
    "# pad the ends of the list with copies of the last element to make them all the same length, using np.vstack\n",
    "gs = [np.vstack([g[:-1], np.repeat(g[-1][None,:], max_len - len(g) + 1, axis = 0)]) for g in gs]\n",
    "data_dict = {n:data[n] for n in data.files}\n",
    "data_dict['geodesics'] = gs\n",
    "data_dict['geodesic_lengths'] = ls\n",
    "np.savez(f'{out_path}/{data_name}.npz', **data_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "autometric",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
