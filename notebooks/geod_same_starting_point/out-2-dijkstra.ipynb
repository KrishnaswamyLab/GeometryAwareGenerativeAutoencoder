{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "85d8aa19",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-03T18:30:57.906704Z",
     "iopub.status.busy": "2024-07-03T18:30:57.906488Z",
     "iopub.status.idle": "2024-07-03T18:31:05.041702Z",
     "shell.execute_reply": "2024-07-03T18:31:05.041258Z"
    },
    "papermill": {
     "duration": 7.142904,
     "end_time": "2024-07-03T18:31:05.043318",
     "exception": false,
     "start_time": "2024-07-03T18:30:57.900414",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO: Using pytorch backend\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO: Note: NumExpr detected 36 cores but \"NUMEXPR_MAX_THREADS\" not set, so enforcing safe limit of 8.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO: NumExpr defaulting to 8 threads.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "from autometric.geodesics import DjikstraGeodesic\n",
    "from autometric.datasets import Hemisphere, Ellipsoid, Saddle, Torus\n",
    "import pathlib\n",
    "import pickle\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "aa65b064",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-03T18:31:05.052564Z",
     "iopub.status.busy": "2024-07-03T18:31:05.052197Z",
     "iopub.status.idle": "2024-07-03T18:31:05.055692Z",
     "shell.execute_reply": "2024-07-03T18:31:05.055341Z"
    },
    "papermill": {
     "duration": 0.009272,
     "end_time": "2024-07-03T18:31:05.056726",
     "exception": false,
     "start_time": "2024-07-03T18:31:05.047454",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "data_path = \"../../data/neurips_results/toy/visualize2/\"\n",
    "data_names = ['hemisphere', 'ellipsoid', 'saddle', 'torus']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "64c2e656",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-03T18:31:05.066042Z",
     "iopub.status.busy": "2024-07-03T18:31:05.065859Z",
     "iopub.status.idle": "2024-07-03T18:31:05.068850Z",
     "shell.execute_reply": "2024-07-03T18:31:05.068518Z"
    },
    "papermill": {
     "duration": 0.00935,
     "end_time": "2024-07-03T18:31:05.069850",
     "exception": false,
     "start_time": "2024-07-03T18:31:05.060500",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "num_points_per_geodesic = 3000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "13359d6c",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-03T18:31:05.079167Z",
     "iopub.status.busy": "2024-07-03T18:31:05.079006Z",
     "iopub.status.idle": "2024-07-03T18:31:05.087726Z",
     "shell.execute_reply": "2024-07-03T18:31:05.087401Z"
    },
    "papermill": {
     "duration": 0.015042,
     "end_time": "2024-07-03T18:31:05.088716",
     "exception": false,
     "start_time": "2024-07-03T18:31:05.073674",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "out_path = '../../data/neurips_results/toy/visualize_gt/'\n",
    "pathlib.Path(out_path).mkdir(parents=True, exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "510c49a9",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-03T18:31:05.097962Z",
     "iopub.status.busy": "2024-07-03T18:31:05.097791Z",
     "iopub.status.idle": "2024-07-03T18:31:05.637268Z",
     "shell.execute_reply": "2024-07-03T18:31:05.636830Z"
    },
    "papermill": {
     "duration": 0.545873,
     "end_time": "2024-07-03T18:31:05.638801",
     "exception": false,
     "start_time": "2024-07-03T18:31:05.092928",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import pickle\n",
    "data_name = 'hemisphere'\n",
    "data = np.load(f'{data_path}/{data_name}.npz')\n",
    "points = data['X']\n",
    "hs = Hemisphere(num_points=3000)\n",
    "hs.X = torch.tensor(points, dtype=torch.float32)\n",
    "start_points = torch.tensor(data['start_points'], dtype=torch.float32)\n",
    "end_points = torch.tensor(data['end_points'], dtype=torch.float32)\n",
    "ts = np.linspace(0, 1, num_points_per_geodesic)\n",
    "gs, ls = hs.geodesics(start_points, end_points, ts)\n",
    "if isinstance(gs[0], torch.Tensor):\n",
    "    gs = [g.detach().numpy() for g in gs]\n",
    "    ls = ls.numpy()\n",
    "max_len = max([len(g) for g in gs])\n",
    "# pad the ends of the list with copies of the last element to make them all the same length, using np.vstack\n",
    "gs = [np.vstack([g[:-1], np.repeat(g[-1][None,:], max_len - len(g) + 1, axis = 0)]) for g in gs]\n",
    "data_dict = {n:data[n] for n in data.files}\n",
    "data_dict['geodesics'] = gs\n",
    "data_dict['geodesic_lengths'] = ls\n",
    "np.savez(f'{out_path}/{data_name}.npz', **data_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ef196845",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-03T18:31:05.649024Z",
     "iopub.status.busy": "2024-07-03T18:31:05.648808Z",
     "iopub.status.idle": "2024-07-03T18:57:53.301863Z",
     "shell.execute_reply": "2024-07-03T18:57:53.301191Z"
    },
    "papermill": {
     "duration": 1607.66359,
     "end_time": "2024-07-03T18:57:53.307034",
     "exception": false,
     "start_time": "2024-07-03T18:31:05.643444",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "data_name = 'ellipsoid'\n",
    "data = np.load(f'{data_path}/{data_name}.npz')\n",
    "points = data['X']\n",
    "hs = Ellipsoid(num_points=3000)\n",
    "hs.X = torch.tensor(points, dtype=torch.float32)\n",
    "start_points = torch.tensor(data['start_points'], dtype=torch.float32)\n",
    "end_points = torch.tensor(data['end_points'], dtype=torch.float32)\n",
    "ts = np.linspace(0, 1, num_points_per_geodesic)\n",
    "gs, ls = hs.geodesics(start_points, end_points, ts)\n",
    "if isinstance(gs[0], torch.Tensor):\n",
    "    gs = [g.detach().numpy() for g in gs]\n",
    "    ls = ls.numpy()\n",
    "max_len = max([len(g) for g in gs])\n",
    "# pad the ends of the list with copies of the last element to make them all the same length, using np.vstack\n",
    "gs = [np.vstack([g[:-1], np.repeat(g[-1][None,:], max_len - len(g) + 1, axis = 0)]) for g in gs]\n",
    "data_dict = {n:data[n] for n in data.files}\n",
    "data_dict['geodesics'] = gs\n",
    "data_dict['geodesic_lengths'] = ls\n",
    "np.savez(f'{out_path}/{data_name}.npz', **data_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "acc02e6e",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-03T18:57:53.333112Z",
     "iopub.status.busy": "2024-07-03T18:57:53.332865Z",
     "iopub.status.idle": "2024-07-03T19:23:23.173607Z",
     "shell.execute_reply": "2024-07-03T19:23:23.172970Z"
    },
    "papermill": {
     "duration": 1529.863912,
     "end_time": "2024-07-03T19:23:23.178294",
     "exception": false,
     "start_time": "2024-07-03T18:57:53.314382",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "data_name = 'saddle'\n",
    "data = np.load(f'{data_path}/{data_name}.npz')\n",
    "points = data['X']\n",
    "hs = Saddle(num_points=3000)\n",
    "hs.X = torch.tensor(points, dtype=torch.float32)\n",
    "start_points = torch.tensor(data['start_points'], dtype=torch.float32)\n",
    "end_points = torch.tensor(data['end_points'], dtype=torch.float32)\n",
    "ts = np.linspace(0, 1, num_points_per_geodesic)\n",
    "gs, ls = hs.geodesics(start_points, end_points, ts)\n",
    "if isinstance(gs[0], torch.Tensor):\n",
    "    gs = [g.detach().numpy() for g in gs]\n",
    "    ls = ls.numpy()\n",
    "max_len = max([len(g) for g in gs])\n",
    "# pad the ends of the list with copies of the last element to make them all the same length, using np.vstack\n",
    "gs = [np.vstack([g[:-1], np.repeat(g[-1][None,:], max_len - len(g) + 1, axis = 0)]) for g in gs]\n",
    "data_dict = {n:data[n] for n in data.files}\n",
    "data_dict['geodesics'] = gs\n",
    "data_dict['geodesic_lengths'] = ls\n",
    "np.savez(f'{out_path}/{data_name}.npz', **data_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "22112184",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-03T19:23:23.213853Z",
     "iopub.status.busy": "2024-07-03T19:23:23.213640Z",
     "iopub.status.idle": "2024-07-03T19:51:41.107193Z",
     "shell.execute_reply": "2024-07-03T19:51:41.106745Z"
    },
    "papermill": {
     "duration": 1697.926982,
     "end_time": "2024-07-03T19:51:41.112110",
     "exception": false,
     "start_time": "2024-07-03T19:23:23.185128",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "data_name = 'torus'\n",
    "data = np.load(f'{data_path}/{data_name}.npz')\n",
    "points = data['X']\n",
    "hs = Torus(num_points=3000)\n",
    "hs.X = torch.tensor(points, dtype=torch.float32)\n",
    "start_points = torch.tensor(data['start_points'], dtype=torch.float32)\n",
    "end_points = torch.tensor(data['end_points'], dtype=torch.float32)\n",
    "ts = np.linspace(0, 1, num_points_per_geodesic)\n",
    "gs, ls = hs.geodesics(start_points, end_points, ts)\n",
    "if isinstance(gs[0], torch.Tensor):\n",
    "    gs = [g.detach().numpy() for g in gs]\n",
    "    ls = ls.numpy()\n",
    "max_len = max([len(g) for g in gs])\n",
    "# pad the ends of the list with copies of the last element to make them all the same length, using np.vstack\n",
    "gs = [np.vstack([g[:-1], np.repeat(g[-1][None,:], max_len - len(g) + 1, axis = 0)]) for g in gs]\n",
    "data_dict = {n:data[n] for n in data.files}\n",
    "data_dict['geodesics'] = gs\n",
    "data_dict['geodesic_lengths'] = ls\n",
    "np.savez(f'{out_path}/{data_name}.npz', **data_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a1a75ee",
   "metadata": {
    "papermill": {
     "duration": 0.003692,
     "end_time": "2024-07-03T19:51:41.123986",
     "exception": false,
     "start_time": "2024-07-03T19:51:41.120294",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "autometric",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 4848.060959,
   "end_time": "2024-07-03T19:51:44.089051",
   "environment_variables": {},
   "exception": null,
   "input_path": "2-dijkstra.ipynb",
   "output_path": "out-2-dijkstra.ipynb",
   "parameters": {},
   "start_time": "2024-07-03T18:30:56.028092",
   "version": "2.4.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}