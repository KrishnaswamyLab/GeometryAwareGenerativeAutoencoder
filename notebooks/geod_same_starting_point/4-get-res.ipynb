{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Failed to detect the name of this notebook, you can set it manually with the WANDB_NOTEBOOK_NAME environment variable to enable code saving.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mxingzhis\u001b[0m. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n"
     ]
    }
   ],
   "source": [
    "import wandb\n",
    "import sys\n",
    "import matplotlib.pyplot as plt\n",
    "import scprep\n",
    "import pandas as pd\n",
    "sys.path.append('../../src/')\n",
    "from train import load_data\n",
    "# from diffusion import DiffusionModel\n",
    "# from evaluate import get_results\n",
    "from omegaconf import OmegaConf\n",
    "# from main import load_data, make_model\n",
    "import numpy as np\n",
    "import os\n",
    "import glob\n",
    "import matplotlib.animation as animation\n",
    "from matplotlib.animation import PillowWriter\n",
    "import torch\n",
    "from model2 import Autoencoder, Preprocessor, Discriminator\n",
    "import magic\n",
    "import torch\n",
    "import pathlib\n",
    "import copy\n",
    "\n",
    "import wandb\n",
    "import sys\n",
    "import matplotlib.pyplot as plt\n",
    "import scprep\n",
    "import pandas as pd\n",
    "from omegaconf import OmegaConf\n",
    "import os\n",
    "import glob\n",
    "import numpy as np\n",
    "import torch\n",
    "from torch import nn\n",
    "import torch.optim as optim\n",
    "from geodesic import jacobian, velocity, CondCurve, GeodesicBridgeOverfit\n",
    "from plotly3d.plot import scatter, trajectories\n",
    "import torch\n",
    "from torch import nn\n",
    "import pytorch_lightning as pl\n",
    "from procrustes import Procrustes\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm import tqdm\n",
    "\n",
    "wandb.login()\n",
    "api = wandb.Api()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_path = \"../../data/neurips_results/toy/visualize/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ours\n",
    "entity = \"xingzhis\"\n",
    "project = \"dmae\"\n",
    "sweep_id = '72pm72bl'\n",
    "sweep = api.sweep(f\"{entity}/{project}/{sweep_id}\")\n",
    "runs_data = []\n",
    "\n",
    "# Iterate through each run in the sweep\n",
    "for run in sweep.runs:\n",
    "    # Extract metrics and configs\n",
    "    metrics = run.summary._json_dict\n",
    "    configs = run.config\n",
    "    \n",
    "    # Combine metrics and configs, and add run ID\n",
    "    combined_data = {**metrics, **configs, \"run_id\": run.id}\n",
    "    \n",
    "    # Append the combined data to the list\n",
    "    runs_data.append(combined_data)\n",
    "\n",
    "# Create a DataFrame from the runs data\n",
    "df = pd.DataFrame(runs_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "names = df[(df['loss_epoch']!='NaN')][['data_name']].values.flatten()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "pathlib.Path('results/ours').mkdir(parents=True, exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "for name in names:\n",
    "    run_id = df[df['data_name'] == name]['run_id'].values[0]\n",
    "    run = api.run(f\"{entity}/{project}/{run_id}\")\n",
    "    folder_path = '../geodesic_on_datasets/wandb/'\n",
    "    cfg = OmegaConf.create(run.config)\n",
    "    folder_list = glob.glob(f\"{folder_path}*{run.id}*\")\n",
    "    ckpt_files = glob.glob(f\"{folder_list[0]}/files/*.ckpt\")\n",
    "    ckpt_path = ckpt_files[0]\n",
    "\n",
    "    ofm = lambda x: x\n",
    "    gbmodel = GeodesicBridgeOverfit.load_from_checkpoint(\n",
    "        checkpoint_path=ckpt_path,\n",
    "        func=ofm,\n",
    "        # func = enc_func,\n",
    "        # discriminator_func=disc_func_pen,\n",
    "        # discriminator_func_for_grad=discriminator_func_for_grad,\n",
    "        input_dim=3, \n",
    "        hidden_dim=64, \n",
    "        scale_factor=1, \n",
    "        symmetric=True, \n",
    "        num_layers=3, \n",
    "        n_tsteps=100, \n",
    "        lr=1e-3, \n",
    "        weight_decay=1e-3,\n",
    "        discriminator_weight=0.,\n",
    "        discriminator_func_for_grad_weight=0.,\n",
    "        id_dim=1,\n",
    "        id_emb_dim=1,\n",
    "        density_weight=0.,\n",
    "        length_weight=1.,\n",
    "    )\n",
    "    data = np.load(f\"{data_path}/{name.split('_')[0]}.npz\")\n",
    "    x = torch.tensor(data['X'], dtype=torch.float32, device=gbmodel.device)\n",
    "    xbatch = torch.tensor(data['start_points'], dtype=x.dtype, device=x.device)\n",
    "    xendbatch = torch.tensor(data['end_points'], dtype=x.dtype, device=x.device)\n",
    "    ids = torch.zeros((xbatch.size(0),1))\n",
    "    x0 = xbatch\n",
    "    x1 = xendbatch\n",
    "    with torch.no_grad():\n",
    "        cc_pts = gbmodel.cc(x0, x1, gbmodel.ts, ids)\n",
    "    np.save(f\"results/ours/{name.split('_')[0]}.npy\", cc_pts.cpu().numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "# no density\n",
    "entity = \"xingzhis\"\n",
    "project = \"dmae\"\n",
    "sweep_id = 'ro5674uj'\n",
    "sweep = api.sweep(f\"{entity}/{project}/{sweep_id}\")\n",
    "runs_data = []\n",
    "\n",
    "# Iterate through each run in the sweep\n",
    "for run in sweep.runs:\n",
    "    # Extract metrics and configs\n",
    "    metrics = run.summary._json_dict\n",
    "    configs = run.config\n",
    "    \n",
    "    # Combine metrics and configs, and add run ID\n",
    "    combined_data = {**metrics, **configs, \"run_id\": run.id}\n",
    "    \n",
    "    # Append the combined data to the list\n",
    "    runs_data.append(combined_data)\n",
    "\n",
    "# Create a DataFrame from the runs data\n",
    "df = pd.DataFrame(runs_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "pathlib.Path('results/no_density').mkdir(parents=True, exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "for name in names:\n",
    "    run_id = df[df['data_name'] == name]['run_id'].values[0]\n",
    "    run = api.run(f\"{entity}/{project}/{run_id}\")\n",
    "    folder_path = '../geodesic_on_datasets/wandb/'\n",
    "    cfg = OmegaConf.create(run.config)\n",
    "    folder_list = glob.glob(f\"{folder_path}*{run.id}*\")\n",
    "    ckpt_files = glob.glob(f\"{folder_list[0]}/files/*.ckpt\")\n",
    "    ckpt_path = ckpt_files[0]\n",
    "\n",
    "    ofm = lambda x: x\n",
    "    gbmodel = GeodesicBridgeOverfit.load_from_checkpoint(\n",
    "        checkpoint_path=ckpt_path,\n",
    "        func=ofm,\n",
    "        # func = enc_func,\n",
    "        # discriminator_func=disc_func_pen,\n",
    "        # discriminator_func_for_grad=discriminator_func_for_grad,\n",
    "        input_dim=3, \n",
    "        hidden_dim=64, \n",
    "        scale_factor=1, \n",
    "        symmetric=True, \n",
    "        num_layers=3, \n",
    "        n_tsteps=100, \n",
    "        lr=1e-3, \n",
    "        weight_decay=1e-3,\n",
    "        discriminator_weight=0.,\n",
    "        discriminator_func_for_grad_weight=0.,\n",
    "        id_dim=1,\n",
    "        id_emb_dim=1,\n",
    "        density_weight=0.,\n",
    "        length_weight=1.,\n",
    "    )\n",
    "    data = np.load(f\"{data_path}/{name.split('_')[0]}.npz\")\n",
    "    x = torch.tensor(data['X'], dtype=torch.float32, device=gbmodel.device)\n",
    "    xbatch = torch.tensor(data['start_points'], dtype=x.dtype, device=x.device)\n",
    "    xendbatch = torch.tensor(data['end_points'], dtype=x.dtype, device=x.device)\n",
    "    ids = torch.zeros((xbatch.size(0),1))\n",
    "    x0 = xbatch\n",
    "    x1 = xendbatch\n",
    "    with torch.no_grad():\n",
    "        cc_pts = gbmodel.cc(x0, x1, gbmodel.ts, ids)\n",
    "    np.save(f\"results/no_density/{name.split('_')[0]}.npy\", cc_pts.cpu().numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
