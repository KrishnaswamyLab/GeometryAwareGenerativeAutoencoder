{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import wandb\n",
    "import sys\n",
    "import matplotlib.pyplot as plt\n",
    "import scprep\n",
    "import pandas as pd\n",
    "sys.path.append('../src/')\n",
    "from evaluate import get_results\n",
    "from omegaconf import OmegaConf\n",
    "from main import load_data, make_model\n",
    "import numpy as np\n",
    "import os\n",
    "import glob\n",
    "import demap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Failed to detect the name of this notebook, you can set it manually with the WANDB_NOTEBOOK_NAME environment variable to enable code saving.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mxingzhis\u001b[0m. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n"
     ]
    }
   ],
   "source": [
    "# Initialize wandb (replace 'your_entity' and 'your_project' with your specific details)\n",
    "wandb.login()\n",
    "api = wandb.Api()\n",
    "\n",
    "# Specify your entity, project, and sweep ID\n",
    "entity = \"xingzhis\"\n",
    "project = \"dmae\"\n",
    "sweep_id = 'wgysuau8'\n",
    "\n",
    "# Fetch the sweep\n",
    "sweep = api.sweep(f\"{entity}/{project}/{sweep_id}\")\n",
    "\n",
    "run_ids = [run.id for run in sweep.runs]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from main import load_data, make_model\n",
    "from data import dataloader_from_pc\n",
    "from procrustes import Procrustes\n",
    "\n",
    "from transformations import LogTransform, NonTransform, StandardScaler, MinMaxScaler, PowerTransformer, KernelTransform\n",
    "\n",
    "from omegaconf import OmegaConf\n",
    "import numpy as np\n",
    "import os\n",
    "import glob\n",
    "from scipy.spatial.distance import pdist, squareform\n",
    "\n",
    "def get_results(run):\n",
    "    cfg = OmegaConf.create(run.config)\n",
    "    folder_path = \"../src/wandb/\"\n",
    "    try:\n",
    "        folder_list = glob.glob(f\"{folder_path}*{run.id}*\")\n",
    "        ckpt_files = glob.glob(f\"{folder_list[0]}/files/*.ckpt\")\n",
    "        ckpt_path = ckpt_files[0]\n",
    "    except:\n",
    "        print(f\"No checkpoint found for run {run.id}\")\n",
    "        return None, None, None\n",
    "    allloader, _, X, phate_coords, colors, dist, pp = load_data(cfg, load_all=True)\n",
    "    emb_dim = phate_coords.shape[1]\n",
    "    data_path = os.path.join(cfg.data.root, cfg.data.name + cfg.data.filetype)\n",
    "    data = np.load(data_path, allow_pickle=True)\n",
    "    dist_std = np.std(data['dist'].flatten())\n",
    "    model = make_model(cfg, X.shape[1], emb_dim, pp, dist_std, from_checkpoint=True, checkpoint_path=ckpt_path)\n",
    "    model.eval()\n",
    "    x_all = next(iter(allloader))['x']\n",
    "    x_pred, z_pred = model(x_all)\n",
    "    x_pred = x_pred.detach().cpu().numpy()\n",
    "    z_pred = z_pred.detach().cpu().numpy()\n",
    "    data_all = data\n",
    "    data_path_train = os.path.join(cfg.data.root, cfg.data.name + cfg.data.filetype)\n",
    "    train_mask = data_all['is_train']\n",
    "    test_mask = ~data_all['is_train']\n",
    "    procrustes = Procrustes()\n",
    "    phate_proc_train, z_hat, disparity = procrustes.fit_transform(data_all['phate'][train_mask], z_pred[train_mask])\n",
    "    zhat_all = procrustes.transform(z_pred)\n",
    "    dist_pred = squareform(pdist(zhat_all))\n",
    "    dist_true = squareform(pdist(data_all['phate']))\n",
    "    test_test_mask = test_mask[:,None] * test_mask[None,:]\n",
    "    test_train_mask = test_mask[:,None] * train_mask[None,:]\n",
    "    train_train_mask = train_mask[:,None] * train_mask[None,:]\n",
    "    test_all_mask = test_mask[:,None] * np.ones_like(test_mask)\n",
    "    eps = 1e-10\n",
    "    dist_mape_test_test = (np.abs(dist_true - dist_pred + eps) / (dist_true + eps) * test_test_mask).sum() / test_test_mask.sum()\n",
    "    dist_mape_test_train = (np.abs(dist_true - dist_pred + eps) / (dist_true + eps) * test_train_mask).sum() / test_train_mask.sum()\n",
    "    dist_mape_train_train = (np.abs(dist_true - dist_pred + eps) / (dist_true + eps) * train_train_mask).sum() / train_train_mask.sum()\n",
    "    dist_mape_test_overall = (np.abs(dist_true - dist_pred + eps) / (dist_true + eps) * test_all_mask).sum() / test_all_mask.sum()\n",
    "    dist_rmse_test_test = np.sqrt(((dist_true - dist_pred)**2 * test_test_mask).sum()/ test_test_mask.sum())\n",
    "    dist_rmse_test_train = np.sqrt(((dist_true - dist_pred)**2 * test_train_mask).sum() / test_train_mask.sum())\n",
    "    dist_rmse_train_train = np.sqrt(((dist_true - dist_pred)**2 * train_train_mask).sum() / train_train_mask.sum())\n",
    "    test_rmse = np.sqrt((data_all['phate'][test_mask] - zhat_all[test_mask])**2).mean()\n",
    "    res = dict(\n",
    "        data=cfg.data.name,\n",
    "        preprocess=cfg.data.preprocess,\n",
    "        kernel=cfg.data.kernel.type if cfg.data.preprocess == 'kernel' else None,\n",
    "        sigma=cfg.data.kernel.sigma if cfg.data.preprocess == 'kernel' else 0,\n",
    "        dist_recon_weight = cfg.model.dist_reconstr_weights,\n",
    "        model_type = cfg.model.type,\n",
    "        dist_mape_test_test=dist_mape_test_test,\n",
    "        dist_mape_test_train=dist_mape_test_train,\n",
    "        dist_mape_test_overall=dist_mape_test_overall,\n",
    "        dist_mape_train_train=dist_mape_train_train,\n",
    "        dist_rmse_test_test=dist_rmse_test_test,\n",
    "        dist_rmse_test_train=dist_rmse_test_train,\n",
    "        dist_rmse_train_train=dist_rmse_train_train,\n",
    "        test_rmse=test_rmse,\n",
    "        train_mask=train_mask\n",
    "    )\n",
    "    plot_data = dict(\n",
    "        phate_true = data_all['phate'][test_mask],\n",
    "        phate_pred = zhat_all[test_mask],\n",
    "        colors = data_all['colors'][test_mask],\n",
    "        colors_train = data_all['colors'][train_mask],\n",
    "        dist_true_test_test = dist_true[test_mask][:,test_mask],\n",
    "        dist_pred_test_test = dist_pred[test_mask][:,test_mask],\n",
    "        dist_true_test_train = dist_true[test_mask][:,train_mask],\n",
    "        dist_pred_test_train = dist_pred[test_mask][:,train_mask],\n",
    "        phate_true_train = data_all['phate'][train_mask],\n",
    "        phate_pred_train = zhat_all[train_mask],\n",
    "        dist_true_train_train = dist_true[train_mask][:,train_mask],\n",
    "        dist_pred_train_train = dist_pred[train_mask][:,train_mask],\n",
    "    )\n",
    "    return res, plot_data, cfg\n",
    "\n",
    "def rename_string(s):\n",
    "    # Split the string into parts\n",
    "    parts = s.split('_')\n",
    "    \n",
    "    # Replace \"noisy\" with \"true\"\n",
    "    parts[0] = \"true\"\n",
    "    \n",
    "    # Remove the last two numbers before \"all\"\n",
    "    new_parts = parts[:-3] + parts[-1:]\n",
    "    \n",
    "    # Reassemble the string\n",
    "    new_s = '_'.join(new_parts)\n",
    "    \n",
    "    return new_s\n",
    "\n",
    "def get_data_config(s):\n",
    "    # Split the string into parts\n",
    "    parts = s.split('_')\n",
    " \n",
    "    \n",
    "    seedmethod = parts[2]+','+parts[1]\n",
    "    bcv=parts[-3]\n",
    "    dropout=parts[-2]\n",
    "    return seedmethod, bcv, dropout"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "res_list = []\n",
    "for run in [sweep.runs[0]]:\n",
    "    res, plots, cfg = get_results(run)\n",
    "    res_list.append(\n",
    "        dict(\n",
    "            run_id=run.id,\n",
    "            res=res,\n",
    "            plots=plots,\n",
    "            cfg=cfg\n",
    "        )\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['phate_true', 'phate_pred', 'colors', 'colors_train', 'dist_true_test_test', 'dist_pred_test_test', 'dist_true_test_train', 'dist_pred_test_train', 'phate_true_train', 'phate_pred_train', 'dist_true_train_train', 'dist_pred_train_train'])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "res_list[0]['plots'].keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([False,  True,  True, ...,  True,  True,  True])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "res_list[0]['res']['train_mask']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "metric_res = []\n",
    "for i in range(len(res_list)):\n",
    "    datatrue = np.load(\"../synthetic_data/\" + rename_string(res_list[i]['res']['data']) + '.npz')\n",
    "    datatrue_train = datatrue['data'][datatrue['is_train']]\n",
    "    datatrue_test = datatrue['data'][~datatrue['is_train']]\n",
    "    phate_train = res_list[i]['plots']['phate_true_train']\n",
    "    phate_test = res_list[i]['plots']['phate_true']\n",
    "    our_train = res_list[i]['plots']['phate_pred_train']\n",
    "    our_test = res_list[i]['plots']['phate_pred']\n",
    "    demap_phate_train = demap.DEMaP(datatrue_train, phate_train)\n",
    "    demap_our_train = demap.DEMaP(datatrue_train, our_train)\n",
    "    demap_phate_test = demap.DEMaP(datatrue_test, phate_test)\n",
    "    demap_our_test = demap.DEMaP(datatrue_test, our_test)\n",
    "    acc_our_train = 1 - res_list[i]['res']['dist_mape_train_train']\n",
    "    acc_our_test = 1 - res_list[i]['res']['dist_mape_test_test']\n",
    "    name = res_list[i]['res']['data']\n",
    "    seedmethod, bcv, dropout = get_data_config(res_list[i]['res']['data'])\n",
    "    metric_res.append(dict(\n",
    "        dataset=seedmethod,\n",
    "        bcv=bcv,\n",
    "        dropout=dropout,\n",
    "        acc_our_train=acc_our_train,\n",
    "        acc_our_test=acc_our_test,\n",
    "        demap_phate_train=demap_phate_train,\n",
    "        demap_our_train=demap_our_train,\n",
    "        demap_our_test=demap_our_test,\n",
    "    ))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "res_df = pd.DataFrame(metric_res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>dataset</th>\n",
       "      <th>bcv</th>\n",
       "      <th>dropout</th>\n",
       "      <th>acc_our_train</th>\n",
       "      <th>acc_our_test</th>\n",
       "      <th>demap_phate_train</th>\n",
       "      <th>demap_our_train</th>\n",
       "      <th>demap_our_test</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>groups,46</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.7</td>\n",
       "      <td>0.790894</td>\n",
       "      <td>0.690511</td>\n",
       "      <td>0.564295</td>\n",
       "      <td>0.537111</td>\n",
       "      <td>0.74691</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     dataset  bcv dropout  acc_our_train  acc_our_test  demap_phate_train  \\\n",
       "0  groups,46  0.2     0.7       0.790894      0.690511           0.564295   \n",
       "\n",
       "   demap_our_train  demap_our_test  \n",
       "0         0.537111         0.74691  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "res_df.sort_values(['dataset', 'bcv', 'dropout'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "res_df.to_csv(\"synth_results.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>dataset</th>\n",
       "      <th>bcv</th>\n",
       "      <th>dropout</th>\n",
       "      <th>acc_our_train</th>\n",
       "      <th>acc_our_test</th>\n",
       "      <th>demap_phate_train</th>\n",
       "      <th>demap_our_train</th>\n",
       "      <th>demap_our_test</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>groups,46</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.7</td>\n",
       "      <td>0.791</td>\n",
       "      <td>0.691</td>\n",
       "      <td>0.564</td>\n",
       "      <td>0.537</td>\n",
       "      <td>0.747</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     dataset  bcv dropout  acc_our_train  acc_our_test  demap_phate_train  \\\n",
       "0  groups,46  0.2     0.7          0.791         0.691              0.564   \n",
       "\n",
       "   demap_our_train  demap_our_test  \n",
       "0            0.537           0.747  "
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "res_df = res_df.sort_values(['dataset', 'bcv', 'dropout'])\n",
    "# Round all numeric columns to 3 decimals, excluding strings\n",
    "rounded_res_df = res_df.select_dtypes(include=['float64']).round(3)\n",
    "# Re-attach the non-numeric columns to the rounded DataFrame\n",
    "for col in res_df.select_dtypes(exclude=['float64']).columns:\n",
    "    rounded_res_df[col] = res_df[col]\n",
    "\n",
    "# Reorder columns to match original DataFrame\n",
    "rounded_res_df = rounded_res_df[res_df.columns]\n",
    "rounded_res_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "geosink",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
