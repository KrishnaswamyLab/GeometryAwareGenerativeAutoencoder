{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import wandb\n",
    "import sys\n",
    "import matplotlib.pyplot as plt\n",
    "import scprep\n",
    "import pandas as pd\n",
    "sys.path.append('../src/')\n",
    "# from diffusion import DiffusionModel\n",
    "# from evaluate import get_results\n",
    "from omegaconf import OmegaConf\n",
    "# from main import load_data, make_model\n",
    "import numpy as np\n",
    "import os\n",
    "import glob\n",
    "import matplotlib.animation as animation\n",
    "from matplotlib.animation import PillowWriter\n",
    "import torch\n",
    "from model2 import Autoencoder, Preprocessor, WDiscriminator\n",
    "from off_manifolder import offmanifolder_maker\n",
    "import magic\n",
    "import torch\n",
    "import pathlib\n",
    "import copy\n",
    "\n",
    "import wandb\n",
    "import sys\n",
    "import matplotlib.pyplot as plt\n",
    "import scprep\n",
    "import pandas as pd\n",
    "from omegaconf import OmegaConf\n",
    "import os\n",
    "import glob\n",
    "import numpy as np\n",
    "import torch\n",
    "from torch import nn\n",
    "import torch.optim as optim\n",
    "from geodesic import jacobian, velocity, CondCurve, GeodesicBridgeOverfit, GeodesicBridge, GeodesicFM\n",
    "from plotly3d.plot import scatter, trajectories\n",
    "import torch\n",
    "from torch import nn\n",
    "import pytorch_lightning as pl\n",
    "from procrustes import Procrustes\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "\n",
    "\n",
    "import hydra\n",
    "from omegaconf import DictConfig, OmegaConf\n",
    "import wandb\n",
    "from pytorch_lightning.loggers import WandbLogger, TensorBoardLogger\n",
    "from pytorch_lightning.callbacks import EarlyStopping, ModelCheckpoint\n",
    "import ot as pot\n",
    "\n",
    "adjoint = False\n",
    "if adjoint:\n",
    "    from torchdiffeq import odeint_adjoint as odeint\n",
    "else:\n",
    "    from torchdiffeq import odeint\n",
    "\n",
    "from train import train_model, load_data\n",
    "from train_dm import load_data as load_data_dm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "from omegaconf import OmegaConf\n",
    "from hydra import initialize, compose\n",
    "import yaml\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('config_ae.yaml', 'r') as file:\n",
    "    override_config = yaml.safe_load(file)\n",
    "\n",
    "def dict_to_overrides(d, prefix=''):\n",
    "    overrides = []\n",
    "    for k, v in d.items():\n",
    "        if isinstance(v, dict):\n",
    "            overrides.extend(dict_to_overrides(v, prefix=f\"{prefix}{k}.\"))\n",
    "        else:\n",
    "            overrides.append(f\"{prefix}{k}={v}\")\n",
    "    return overrides\n",
    "\n",
    "overrides = dict_to_overrides(override_config)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/tmp.6Ory2GY19m/ipykernel_572973/2365906557.py:1: UserWarning: \n",
      "The version_base parameter is not specified.\n",
      "Please specify a compatability version level, or None.\n",
      "Will assume defaults for version 1.1\n",
      "  initialize(config_path=\".\")\n"
     ]
    }
   ],
   "source": [
    "initialize(config_path=\".\")\n",
    "cfg = compose(config_name=\"config\", overrides=overrides)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/gpfs/gibbs/pi/krishnaswamy_smita/xingzhi/.conda_envs/geosink/lib/python3.11/site-packages/pytorch_lightning/utilities/parsing.py:269: UserWarning: Attribute 'preprocessor' is an instance of `nn.Module` and is already saved during checkpointing. It is recommended to ignore them using `self.save_hyperparameters(ignore=['preprocessor'])`.\n",
      "  rank_zero_warn(\n",
      "/gpfs/gibbs/pi/krishnaswamy_smita/xingzhi/.conda_envs/geosink/lib/python3.11/site-packages/lightning_fabric/plugins/environments/slurm.py:165: PossibleUserWarning: The `srun` command is available on your system but is not used. HINT: If your intention is to run Lightning on SLURM, prepend your python command with `srun` like so: srun python /gpfs/gibbs/pi/krishnaswamy_smita/xingzhi/.conda_env ...\n",
      "  rank_zero_warn(\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "You are using a CUDA device ('NVIDIA RTX A5000') that has Tensor Cores. To properly utilize them, you should set `torch.set_float32_matmul_precision('medium' | 'high')` which will trade-off precision for performance. For more details, read https://pytorch.org/docs/stable/generated/torch.set_float32_matmul_precision.html#torch.set_float32_matmul_precision\n",
      "/gpfs/gibbs/pi/krishnaswamy_smita/xingzhi/.conda_envs/geosink/lib/python3.11/site-packages/pytorch_lightning/callbacks/model_checkpoint.py:613: UserWarning: Checkpoint directory ./results_ae/ exists and is not empty.\n",
      "  rank_zero_warn(f\"Checkpoint directory {dirpath} exists and is not empty.\")\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "\n",
      "  | Name    | Type    | Params\n",
      "------------------------------------\n",
      "0 | encoder | Encoder | 8.8 K \n",
      "1 | decoder | Decoder | 8.8 K \n",
      "------------------------------------\n",
      "17.5 K    Trainable params\n",
      "0         Non-trainable params\n",
      "17.5 K    Total params\n",
      "0.070     Total estimated model params size (MB)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "885e397e25ac42ada618ba643219509e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Sanity Checking: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/gpfs/gibbs/pi/krishnaswamy_smita/xingzhi/.conda_envs/geosink/lib/python3.11/site-packages/pytorch_lightning/trainer/connectors/data_connector.py:488: PossibleUserWarning: Your `val_dataloader`'s sampler has shuffling enabled, it is strongly recommended that you turn shuffling off for val/test/predict dataloaders.\n",
      "  rank_zero_warn(\n",
      "/gpfs/gibbs/pi/krishnaswamy_smita/xingzhi/.conda_envs/geosink/lib/python3.11/site-packages/pytorch_lightning/trainer/connectors/data_connector.py:224: PossibleUserWarning: The dataloader, val_dataloader 0, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 32 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.\n",
      "  rank_zero_warn(\n",
      "/gpfs/gibbs/pi/krishnaswamy_smita/xingzhi/.conda_envs/geosink/lib/python3.11/site-packages/pytorch_lightning/utilities/data.py:83: UserWarning: Trying to infer the `batch_size` from an ambiguous collection. The batch size we found is 256. To avoid any miscalculations, use `self.log(..., batch_size=batch_size)`.\n",
      "  warning_cache.warn(\n",
      "/gpfs/gibbs/pi/krishnaswamy_smita/xingzhi/.conda_envs/geosink/lib/python3.11/site-packages/pytorch_lightning/trainer/connectors/data_connector.py:224: PossibleUserWarning: The dataloader, train_dataloader, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 32 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.\n",
      "  rank_zero_warn(\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cb9a340fc64d446eabb9993e15789ed8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a619eee6ad7e455e9033e3e60a1bf892",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a77cbbaf6e0d42f58fece4ff2fb528af",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5016298a289c47d5b64535fda7525f96",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3136c408a6fa41a9ad98602b6c082ee1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7f213f45f42d4c60a6c5b5d3f8d637f5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "724d3b2f04a74b76879b6ea9343d61f8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f0c423f58a9843dd93deb974a51cbeeb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7fd247ceabc84e80bfbd715296e973f5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "93adafe64d6049c4b7ce58c86baefaf6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d7ff4f82499c4b19bf50d4e5800b42a9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=10` reached.\n"
     ]
    }
   ],
   "source": [
    "trainloader, valloader, X, phate_coords, colors, preprocessor = load_data(cfg)\n",
    "cfg.dimensions.data = X.shape[1]\n",
    "if cfg.training.mode == 'discriminator':\n",
    "    model = Discriminator(cfg, preprocessor)\n",
    "elif cfg.training.mode == 'noise_predictor':\n",
    "    model = NoisePredictor(cfg, preprocessor)\n",
    "elif cfg.training.mode == 'wdiscriminator':\n",
    "    model = WDiscriminator(cfg, preprocessor)\n",
    "elif cfg.training.mode == 'sphere':\n",
    "    model = SphereEncoder(cfg, preprocessor)\n",
    "elif cfg.training.mode == 'hyperbolic':\n",
    "    model = HyperbolicLorenzEncoder(cfg, preprocessor)\n",
    "elif cfg.training.mode == 'fimm':\n",
    "    model = FIMMEncoder(cfg, preprocessor)\n",
    "else:\n",
    "    model = Autoencoder(cfg, preprocessor)\n",
    "if cfg.logger.use_wandb:\n",
    "    logger = WandbLogger()\n",
    "    checkpoint_callback = ModelCheckpoint(\n",
    "        dirpath=wandb.run.dir,  # Save checkpoints in wandb directory\n",
    "        save_top_k=1,  # Save the top 1 model\n",
    "        monitor=cfg.training.monitor,  # Model selection based on validation loss\n",
    "        mode='min'  # Minimize validation loss\n",
    "    )\n",
    "else:\n",
    "    logger = TensorBoardLogger(save_dir=os.path.join(cfg.path.root, cfg.path.log))\n",
    "    checkpoint_callback = ModelCheckpoint(\n",
    "        dirpath=cfg.path.root,  # Save checkpoints in wandb directory\n",
    "        filename=cfg.path.model,\n",
    "        save_top_k=1,\n",
    "        monitor=cfg.training.monitor,  # Model selection based on validation loss\n",
    "        mode='min'  # Minimize validation loss\n",
    "    )\n",
    "if cfg.training.mode in ['discriminator', 'wdiscriminator', 'noise_predictor', 'sphere', 'hyperbolic', 'fimm']:\n",
    "    train_model(cfg, model, trainloader, valloader, logger, checkpoint_callback)\n",
    "elif cfg.training.mode == 'separate':\n",
    "    cfg.training.mode = 'encoder'\n",
    "    train_model(cfg, model.encoder, trainloader, valloader, logger, checkpoint_callback)\n",
    "    model.link_encoder()\n",
    "    cfg.training.mode = 'decoder'\n",
    "    train_model(cfg, model.decoder, trainloader, valloader, logger, checkpoint_callback)\n",
    "elif cfg.training.mode in ['end2end', 'negative', 'radius']: # encoder-only, decoder-only, or end-to-end\n",
    "    train_model(cfg, model, trainloader, valloader, logger, checkpoint_callback)\n",
    "elif cfg.training.mode == 'encoder':\n",
    "    train_model(cfg, model.encoder, trainloader, valloader, logger, checkpoint_callback)\n",
    "elif cfg.training.mode == 'decoder':\n",
    "    train_model(cfg, model.decoder, trainloader, valloader, logger, checkpoint_callback)\n",
    "else:\n",
    "    raise ValueError('Invalid training mode')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('config_disc.yaml', 'r') as file:\n",
    "    override_config = yaml.safe_load(file)\n",
    "\n",
    "def dict_to_overrides(d, prefix=''):\n",
    "    overrides = []\n",
    "    for k, v in d.items():\n",
    "        if isinstance(v, dict):\n",
    "            overrides.extend(dict_to_overrides(v, prefix=f\"{prefix}{k}.\"))\n",
    "        else:\n",
    "            overrides.append(f\"{prefix}{k}={v}\")\n",
    "    return overrides\n",
    "\n",
    "overrides = dict_to_overrides(override_config)\n",
    "cfg_disc = compose(config_name=\"config\", overrides=overrides)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "You are using a CUDA device ('NVIDIA RTX A5000') that has Tensor Cores. To properly utilize them, you should set `torch.set_float32_matmul_precision('medium' | 'high')` which will trade-off precision for performance. For more details, read https://pytorch.org/docs/stable/generated/torch.set_float32_matmul_precision.html#torch.set_float32_matmul_precision\n",
      "/gpfs/gibbs/pi/krishnaswamy_smita/xingzhi/.conda_envs/geosink/lib/python3.11/site-packages/pytorch_lightning/callbacks/model_checkpoint.py:613: UserWarning: Checkpoint directory ./results_wd/ exists and is not empty.\n",
      "  rank_zero_warn(f\"Checkpoint directory {dirpath} exists and is not empty.\")\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "\n",
      "  | Name         | Type         | Params\n",
      "----------------------------------------------\n",
      "0 | preprocessor | Preprocessor | 0     \n",
      "1 | mlp          | MLP          | 8.6 K \n",
      "----------------------------------------------\n",
      "8.6 K     Trainable params\n",
      "0         Non-trainable params\n",
      "8.6 K     Total params\n",
      "0.035     Total estimated model params size (MB)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a4461da93eff4ec39e9b3d0df3902883",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Sanity Checking: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3a4ecdc04a9e450a8cfe96ebb6a4b0ba",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "afd10ffcaf71479ea5a10e59166cfb59",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6c0fbf0776494e03abbc85a6becd2595",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "aaed5f3c294049d08979b4e1024b1316",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bf388bfc384043a4a0909cad8d2144b1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b9d1b394fe1c4f48aea95b39f3f42f65",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ea37b87a3a16479f8bfb5cd7aac18346",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0895ad21eaff4fc2bdabc9bfa2e47690",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "af65a0b4609c4161b93c40de53cc3932",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "109f2c7c4aca4efca63e4226a13eeb40",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7d7f21dc6a1e4fc687e9c8a400e785ab",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=10` reached.\n"
     ]
    }
   ],
   "source": [
    "trainloader, valloader, X, phate_coords, colors, preprocessor = load_data(cfg_disc)\n",
    "cfg_disc.dimensions.data = X.shape[1]\n",
    "if cfg_disc.training.mode == 'discriminator':\n",
    "    wmodel = Discriminator(cfg_disc, preprocessor)\n",
    "elif cfg_disc.training.mode == 'noise_predictor':\n",
    "    wmodel = NoisePredictor(cfg_disc, preprocessor)\n",
    "elif cfg_disc.training.mode == 'wdiscriminator':\n",
    "    wmodel = WDiscriminator(cfg_disc, preprocessor)\n",
    "elif cfg_disc.training.mode == 'sphere':\n",
    "    wmodel = SphereEncoder(cfg_disc, preprocessor)\n",
    "elif cfg_disc.training.mode == 'hyperbolic':\n",
    "    wmodel = HyperbolicLorenzEncoder(cfg_disc, preprocessor)\n",
    "elif cfg_disc.training.mode == 'fimm':\n",
    "    wmodel = FIMMEncoder(cfg_disc, preprocessor)\n",
    "else:\n",
    "    wmodel = Autoencoder(cfg_disc, preprocessor)\n",
    "if cfg_disc.logger.use_wandb:\n",
    "    logger = WandbLogger()\n",
    "    checkpoint_callback = ModelCheckpoint(\n",
    "        dirpath=wandb.run.dir,  # Save checkpoints in wandb directory\n",
    "        save_top_k=1,  # Save the top 1 model\n",
    "        monitor=cfg_disc.training.monitor,  # Model selection based on validation loss\n",
    "        mode='min'  # Minimize validation loss\n",
    "    )\n",
    "else:\n",
    "    logger = TensorBoardLogger(save_dir=os.path.join(cfg_disc.path.root, cfg_disc.path.log))\n",
    "    checkpoint_callback = ModelCheckpoint(\n",
    "        dirpath=cfg_disc.path.root,  # Save checkpoints in wandb directory\n",
    "        filename=cfg_disc.path.model,\n",
    "        save_top_k=1,\n",
    "        monitor=cfg_disc.training.monitor,  # Model selection based on validation loss\n",
    "        mode='min'  # Minimize validation loss\n",
    "    )\n",
    "if cfg_disc.training.mode in ['discriminator', 'wdiscriminator', 'noise_predictor', 'sphere', 'hyperbolic', 'fimm']:\n",
    "    train_model(cfg_disc, wmodel, trainloader, valloader, logger, checkpoint_callback)\n",
    "elif cfg_disc.training.mode == 'separate':\n",
    "    cfg_disc.training.mode = 'encoder'\n",
    "    train_model(cfg_disc, wmodel.encoder, trainloader, valloader, logger, checkpoint_callback)\n",
    "    wmodel.link_encoder()\n",
    "    cfg_disc.training.mode = 'decoder'\n",
    "    train_model(cfg_disc, wmodel.decoder, trainloader, valloader, logger, checkpoint_callback)\n",
    "elif cfg_disc.training.mode in ['end2end', 'negative', 'radius']: # encoder-only, decoder-only, or end-to-end\n",
    "    train_model(cfg_disc, wmodel, trainloader, valloader, logger, checkpoint_callback)\n",
    "elif cfg_disc.training.mode == 'encoder':\n",
    "    train_model(cfg_disc, wmodel.encoder, trainloader, valloader, logger, checkpoint_callback)\n",
    "elif cfg_disc.training.mode == 'decoder':\n",
    "    train_model(cfg_disc, wmodel.decoder, trainloader, valloader, logger, checkpoint_callback)\n",
    "else:\n",
    "    raise ValueError('Invalid training mode')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "geosink",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
